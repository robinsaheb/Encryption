{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('creditcard.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n",
      "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
      "       'Class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31 columns, 2 of which are Time and Amount. The rest are output from the PCA transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not Fraud    284315\n",
       "Fraud           492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Class.value_counts().rename(index = {0:'Not Fraud', 1:'Fraud'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 285k transactions just 492 were labelled as fraudulent, it is a small percentage but may represent billions of dollars of lost revenue each year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PCA done on the dataset transformed it into standard-normal form. I will do the same to the 'time' and 'amount' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Time'] = StandardScaler().fit_transform(data['Time'].values.reshape(-1, 1))\n",
    "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data into training and testing sets, And To evaluate the performance of our model we will training our model on the legitimate transactions,only, And Reserving the correct class on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = train_test_split(data,test_size = 0.3,random_state=42)\n",
    "train_x = train_x[train_x.Class == 0] \n",
    "train_x = train_x.drop(['Class'], axis=1) \n",
    "\n",
    "\n",
    "test_y = test_x['Class']\n",
    "test_x = test_x.drop(['Class'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Autoencoder uses 4 Desnse (fully connected) layers with 14, 7, 7 and 30 neurons respectively. The first two layers are used for our encoder, the last two go for the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_x.shape[1]\n",
    "encoding_dim = int(input_dim / 2) - 1\n",
    "hidden_dim = int(encoding_dim / 2)\n",
    "learning_rate = 1e-7\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
    "decoder = Dense(hidden_dim, activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train our model for 100 epochs with a batch size of 128 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 100\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Model Checkpoint to save the best model and TensorBoard for graph visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/1555 [..............................] - ETA: 0s - loss: 1.0213 - accuracy: 0.0078WARNING:tensorflow:From /Users/sahebsingh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1555 [..............................] - ETA: 50s - loss: 1.1089 - accuracy: 0.0273WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0032s vs `on_train_batch_end` time: 0.0615s). Check your callbacks.\n",
      "1555/1555 [==============================] - 2s 1ms/step - loss: 0.9092 - accuracy: 0.3488 - val_loss: 0.8470 - val_accuracy: 0.5673\n",
      "Epoch 2/100\n",
      "1555/1555 [==============================] - 1s 842us/step - loss: 0.8050 - accuracy: 0.5955 - val_loss: 0.7919 - val_accuracy: 0.6408\n",
      "Epoch 3/100\n",
      "1555/1555 [==============================] - 1s 869us/step - loss: 0.7611 - accuracy: 0.6458 - val_loss: 0.7728 - val_accuracy: 0.6450\n",
      "Epoch 4/100\n",
      "1555/1555 [==============================] - 1s 860us/step - loss: 0.7482 - accuracy: 0.6453 - val_loss: 0.7651 - val_accuracy: 0.6470\n",
      "Epoch 5/100\n",
      "1555/1555 [==============================] - 1s 859us/step - loss: 0.7414 - accuracy: 0.6476 - val_loss: 0.7608 - val_accuracy: 0.6500\n",
      "Epoch 6/100\n",
      "1555/1555 [==============================] - 1s 851us/step - loss: 0.7367 - accuracy: 0.6503 - val_loss: 0.7575 - val_accuracy: 0.6524\n",
      "Epoch 7/100\n",
      "1555/1555 [==============================] - 1s 883us/step - loss: 0.7335 - accuracy: 0.6542 - val_loss: 0.7557 - val_accuracy: 0.6535\n",
      "Epoch 8/100\n",
      "1555/1555 [==============================] - 1s 837us/step - loss: 0.7311 - accuracy: 0.6578 - val_loss: 0.7524 - val_accuracy: 0.6551\n",
      "Epoch 9/100\n",
      "1555/1555 [==============================] - 1s 837us/step - loss: 0.7293 - accuracy: 0.6609 - val_loss: 0.7517 - val_accuracy: 0.6587\n",
      "Epoch 10/100\n",
      "1555/1555 [==============================] - 1s 833us/step - loss: 0.7282 - accuracy: 0.6626 - val_loss: 0.7503 - val_accuracy: 0.6621\n",
      "Epoch 11/100\n",
      "1555/1555 [==============================] - 1s 851us/step - loss: 0.7271 - accuracy: 0.6635 - val_loss: 0.7493 - val_accuracy: 0.6661\n",
      "Epoch 12/100\n",
      "1555/1555 [==============================] - 1s 843us/step - loss: 0.7260 - accuracy: 0.6646 - val_loss: 0.7489 - val_accuracy: 0.6668\n",
      "Epoch 13/100\n",
      "1555/1555 [==============================] - 1s 852us/step - loss: 0.7254 - accuracy: 0.6653 - val_loss: 0.7496 - val_accuracy: 0.6636\n",
      "Epoch 14/100\n",
      "1555/1555 [==============================] - 1s 871us/step - loss: 0.7244 - accuracy: 0.6661 - val_loss: 0.7488 - val_accuracy: 0.6634\n",
      "Epoch 15/100\n",
      "1555/1555 [==============================] - 1s 857us/step - loss: 0.7240 - accuracy: 0.6673 - val_loss: 0.7475 - val_accuracy: 0.6688\n",
      "Epoch 16/100\n",
      "1555/1555 [==============================] - 1s 854us/step - loss: 0.7232 - accuracy: 0.6685 - val_loss: 0.7469 - val_accuracy: 0.6664\n",
      "Epoch 17/100\n",
      "1555/1555 [==============================] - 1s 853us/step - loss: 0.7226 - accuracy: 0.6695 - val_loss: 0.7466 - val_accuracy: 0.6668\n",
      "Epoch 18/100\n",
      "1555/1555 [==============================] - 1s 847us/step - loss: 0.7219 - accuracy: 0.6706 - val_loss: 0.7461 - val_accuracy: 0.6696\n",
      "Epoch 19/100\n",
      "1555/1555 [==============================] - 1s 855us/step - loss: 0.7217 - accuracy: 0.6712 - val_loss: 0.7454 - val_accuracy: 0.6712\n",
      "Epoch 20/100\n",
      "1555/1555 [==============================] - 1s 862us/step - loss: 0.7212 - accuracy: 0.6725 - val_loss: 0.7457 - val_accuracy: 0.6684\n",
      "Epoch 21/100\n",
      "1555/1555 [==============================] - 1s 852us/step - loss: 0.7207 - accuracy: 0.6742 - val_loss: 0.7446 - val_accuracy: 0.6797\n",
      "Epoch 22/100\n",
      "1555/1555 [==============================] - 1s 852us/step - loss: 0.7205 - accuracy: 0.6757 - val_loss: 0.7467 - val_accuracy: 0.6770\n",
      "Epoch 23/100\n",
      "1555/1555 [==============================] - 1s 854us/step - loss: 0.7203 - accuracy: 0.6768 - val_loss: 0.7459 - val_accuracy: 0.6696\n",
      "Epoch 24/100\n",
      "1555/1555 [==============================] - 1s 850us/step - loss: 0.7199 - accuracy: 0.6780 - val_loss: 0.7442 - val_accuracy: 0.6766\n",
      "Epoch 25/100\n",
      "1555/1555 [==============================] - 1s 865us/step - loss: 0.7195 - accuracy: 0.6802 - val_loss: 0.7442 - val_accuracy: 0.6780\n",
      "Epoch 26/100\n",
      "1555/1555 [==============================] - 1s 860us/step - loss: 0.7191 - accuracy: 0.6817 - val_loss: 0.7444 - val_accuracy: 0.6782\n",
      "Epoch 27/100\n",
      "1555/1555 [==============================] - 1s 868us/step - loss: 0.7187 - accuracy: 0.6831 - val_loss: 0.7429 - val_accuracy: 0.6831\n",
      "Epoch 28/100\n",
      "1555/1555 [==============================] - 1s 875us/step - loss: 0.7187 - accuracy: 0.6848 - val_loss: 0.7427 - val_accuracy: 0.6831\n",
      "Epoch 29/100\n",
      "1555/1555 [==============================] - 1s 871us/step - loss: 0.7186 - accuracy: 0.6860 - val_loss: 0.7425 - val_accuracy: 0.6843\n",
      "Epoch 30/100\n",
      "1555/1555 [==============================] - 1s 854us/step - loss: 0.7178 - accuracy: 0.6878 - val_loss: 0.7431 - val_accuracy: 0.6873\n",
      "Epoch 31/100\n",
      "1555/1555 [==============================] - 1s 849us/step - loss: 0.7177 - accuracy: 0.6884 - val_loss: 0.7431 - val_accuracy: 0.6885\n",
      "Epoch 32/100\n",
      "1555/1555 [==============================] - 1s 874us/step - loss: 0.7178 - accuracy: 0.6889 - val_loss: 0.7424 - val_accuracy: 0.6813\n",
      "Epoch 33/100\n",
      "1555/1555 [==============================] - 1s 924us/step - loss: 0.7173 - accuracy: 0.6902 - val_loss: 0.7414 - val_accuracy: 0.6904\n",
      "Epoch 34/100\n",
      "1555/1555 [==============================] - 1s 886us/step - loss: 0.7175 - accuracy: 0.6900 - val_loss: 0.7424 - val_accuracy: 0.6939\n",
      "Epoch 35/100\n",
      "1555/1555 [==============================] - 1s 897us/step - loss: 0.7169 - accuracy: 0.6919 - val_loss: 0.7421 - val_accuracy: 0.6941\n",
      "Epoch 36/100\n",
      "1555/1555 [==============================] - 1s 889us/step - loss: 0.7168 - accuracy: 0.6912 - val_loss: 0.7419 - val_accuracy: 0.6959\n",
      "Epoch 37/100\n",
      "1555/1555 [==============================] - 1s 842us/step - loss: 0.7166 - accuracy: 0.6924 - val_loss: 0.7415 - val_accuracy: 0.6892\n",
      "Epoch 38/100\n",
      "1555/1555 [==============================] - 1s 848us/step - loss: 0.7162 - accuracy: 0.6936 - val_loss: 0.7420 - val_accuracy: 0.6942\n",
      "Epoch 39/100\n",
      "1555/1555 [==============================] - 1s 896us/step - loss: 0.7159 - accuracy: 0.6934 - val_loss: 0.7415 - val_accuracy: 0.6905\n",
      "Epoch 40/100\n",
      "1555/1555 [==============================] - 2s 1ms/step - loss: 0.7160 - accuracy: 0.6932 - val_loss: 0.7420 - val_accuracy: 0.6971\n",
      "Epoch 41/100\n",
      "1555/1555 [==============================] - 1s 944us/step - loss: 0.7156 - accuracy: 0.6942 - val_loss: 0.7406 - val_accuracy: 0.6911\n",
      "Epoch 42/100\n",
      "1555/1555 [==============================] - 1s 953us/step - loss: 0.7167 - accuracy: 0.6918 - val_loss: 0.7427 - val_accuracy: 0.6885\n",
      "Epoch 43/100\n",
      "1555/1555 [==============================] - 1s 886us/step - loss: 0.7156 - accuracy: 0.6942 - val_loss: 0.7405 - val_accuracy: 0.6973\n",
      "Epoch 44/100\n",
      "1555/1555 [==============================] - 1s 856us/step - loss: 0.7152 - accuracy: 0.6944 - val_loss: 0.7407 - val_accuracy: 0.6967\n",
      "Epoch 45/100\n",
      "1555/1555 [==============================] - 1s 852us/step - loss: 0.7151 - accuracy: 0.6950 - val_loss: 0.7423 - val_accuracy: 0.6853\n",
      "Epoch 46/100\n",
      "1555/1555 [==============================] - 1s 888us/step - loss: 0.7152 - accuracy: 0.6947 - val_loss: 0.7417 - val_accuracy: 0.6981\n",
      "Epoch 47/100\n",
      "1555/1555 [==============================] - 1s 919us/step - loss: 0.7148 - accuracy: 0.6963 - val_loss: 0.7411 - val_accuracy: 0.6971\n",
      "Epoch 48/100\n",
      "1555/1555 [==============================] - 1s 894us/step - loss: 0.7149 - accuracy: 0.6953 - val_loss: 0.7406 - val_accuracy: 0.6996\n",
      "Epoch 49/100\n",
      "1555/1555 [==============================] - 1s 886us/step - loss: 0.7148 - accuracy: 0.6960 - val_loss: 0.7404 - val_accuracy: 0.6991\n",
      "Epoch 50/100\n",
      "1555/1555 [==============================] - 1s 877us/step - loss: 0.7147 - accuracy: 0.6968 - val_loss: 0.7403 - val_accuracy: 0.6974\n",
      "Epoch 51/100\n",
      "1555/1555 [==============================] - 1s 867us/step - loss: 0.7147 - accuracy: 0.6962 - val_loss: 0.7407 - val_accuracy: 0.6946\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1555/1555 [==============================] - 1s 853us/step - loss: 0.7144 - accuracy: 0.6962 - val_loss: 0.7403 - val_accuracy: 0.6960\n",
      "Epoch 53/100\n",
      "1555/1555 [==============================] - 1s 858us/step - loss: 0.7146 - accuracy: 0.6971 - val_loss: 0.7410 - val_accuracy: 0.6989\n",
      "Epoch 54/100\n",
      "1555/1555 [==============================] - 1s 858us/step - loss: 0.7146 - accuracy: 0.6971 - val_loss: 0.7409 - val_accuracy: 0.6996\n",
      "Epoch 55/100\n",
      "1555/1555 [==============================] - 1s 845us/step - loss: 0.7142 - accuracy: 0.6977 - val_loss: 0.7415 - val_accuracy: 0.6975\n",
      "Epoch 56/100\n",
      "1555/1555 [==============================] - 1s 816us/step - loss: 0.7143 - accuracy: 0.6972 - val_loss: 0.7415 - val_accuracy: 0.6965\n",
      "Epoch 57/100\n",
      "1555/1555 [==============================] - 1s 826us/step - loss: 0.7143 - accuracy: 0.6978 - val_loss: 0.7405 - val_accuracy: 0.6987\n",
      "Epoch 58/100\n",
      "1555/1555 [==============================] - 2s 1ms/step - loss: 0.7144 - accuracy: 0.6974 - val_loss: 0.7418 - val_accuracy: 0.6999\n",
      "Epoch 59/100\n",
      "1555/1555 [==============================] - 2s 996us/step - loss: 0.7139 - accuracy: 0.6979 - val_loss: 0.7404 - val_accuracy: 0.6981\n",
      "Epoch 60/100\n",
      "1555/1555 [==============================] - 1s 876us/step - loss: 0.7142 - accuracy: 0.6978 - val_loss: 0.7411 - val_accuracy: 0.7005\n",
      "Epoch 61/100\n",
      "1555/1555 [==============================] - 1s 910us/step - loss: 0.7140 - accuracy: 0.6980 - val_loss: 0.7412 - val_accuracy: 0.6909\n",
      "Epoch 62/100\n",
      "1555/1555 [==============================] - 1s 885us/step - loss: 0.7140 - accuracy: 0.6979 - val_loss: 0.7409 - val_accuracy: 0.7017\n",
      "Epoch 63/100\n",
      "1555/1555 [==============================] - 1s 816us/step - loss: 0.7140 - accuracy: 0.6987 - val_loss: 0.7406 - val_accuracy: 0.7018\n",
      "Epoch 64/100\n",
      "1555/1555 [==============================] - 1s 835us/step - loss: 0.7138 - accuracy: 0.6990 - val_loss: 0.7402 - val_accuracy: 0.7011\n",
      "Epoch 65/100\n",
      "1555/1555 [==============================] - 1s 829us/step - loss: 0.7138 - accuracy: 0.6982 - val_loss: 0.7402 - val_accuracy: 0.7010\n",
      "Epoch 66/100\n",
      "1555/1555 [==============================] - 1s 829us/step - loss: 0.7140 - accuracy: 0.6986 - val_loss: 0.7408 - val_accuracy: 0.7010\n",
      "Epoch 67/100\n",
      "1555/1555 [==============================] - 1s 840us/step - loss: 0.7136 - accuracy: 0.6989 - val_loss: 0.7426 - val_accuracy: 0.6913\n",
      "Epoch 68/100\n",
      "1555/1555 [==============================] - 1s 948us/step - loss: 0.7137 - accuracy: 0.6986 - val_loss: 0.7403 - val_accuracy: 0.6975\n",
      "Epoch 69/100\n",
      "1555/1555 [==============================] - 1s 846us/step - loss: 0.7135 - accuracy: 0.6990 - val_loss: 0.7404 - val_accuracy: 0.7019\n",
      "Epoch 70/100\n",
      "1555/1555 [==============================] - 1s 853us/step - loss: 0.7135 - accuracy: 0.6993 - val_loss: 0.7407 - val_accuracy: 0.7060\n",
      "Epoch 71/100\n",
      "1555/1555 [==============================] - 1s 849us/step - loss: 0.7135 - accuracy: 0.6990 - val_loss: 0.7402 - val_accuracy: 0.6978\n",
      "Epoch 72/100\n",
      "1555/1555 [==============================] - 1s 858us/step - loss: 0.7134 - accuracy: 0.6995 - val_loss: 0.7406 - val_accuracy: 0.7006\n",
      "Epoch 73/100\n",
      "1555/1555 [==============================] - 1s 834us/step - loss: 0.7137 - accuracy: 0.6983 - val_loss: 0.7406 - val_accuracy: 0.7043\n",
      "Epoch 74/100\n",
      "1555/1555 [==============================] - 1s 826us/step - loss: 0.7133 - accuracy: 0.6997 - val_loss: 0.7405 - val_accuracy: 0.7019\n",
      "Epoch 75/100\n",
      "1555/1555 [==============================] - 1s 840us/step - loss: 0.7132 - accuracy: 0.6988 - val_loss: 0.7407 - val_accuracy: 0.6983\n",
      "Epoch 76/100\n",
      "1555/1555 [==============================] - 1s 871us/step - loss: 0.7132 - accuracy: 0.6993 - val_loss: 0.7406 - val_accuracy: 0.7007\n",
      "Epoch 77/100\n",
      "1555/1555 [==============================] - 1s 827us/step - loss: 0.7132 - accuracy: 0.6987 - val_loss: 0.7406 - val_accuracy: 0.7001\n",
      "Epoch 78/100\n",
      "1555/1555 [==============================] - 1s 834us/step - loss: 0.7132 - accuracy: 0.6983 - val_loss: 0.7400 - val_accuracy: 0.6992\n",
      "Epoch 79/100\n",
      "1555/1555 [==============================] - 1s 825us/step - loss: 0.7131 - accuracy: 0.6990 - val_loss: 0.7403 - val_accuracy: 0.6976\n",
      "Epoch 80/100\n",
      "1555/1555 [==============================] - 1s 821us/step - loss: 0.7132 - accuracy: 0.6987 - val_loss: 0.7410 - val_accuracy: 0.6947\n",
      "Epoch 81/100\n",
      "1555/1555 [==============================] - 1s 822us/step - loss: 0.7131 - accuracy: 0.6983 - val_loss: 0.7413 - val_accuracy: 0.6982\n",
      "Epoch 82/100\n",
      "1555/1555 [==============================] - 1s 821us/step - loss: 0.7132 - accuracy: 0.6985 - val_loss: 0.7402 - val_accuracy: 0.7007\n",
      "Epoch 83/100\n",
      "1555/1555 [==============================] - 1s 832us/step - loss: 0.7129 - accuracy: 0.6999 - val_loss: 0.7405 - val_accuracy: 0.7010\n",
      "Epoch 84/100\n",
      "1555/1555 [==============================] - 1s 828us/step - loss: 0.7129 - accuracy: 0.6989 - val_loss: 0.7404 - val_accuracy: 0.7002\n",
      "Epoch 85/100\n",
      "1555/1555 [==============================] - 1s 816us/step - loss: 0.7129 - accuracy: 0.6990 - val_loss: 0.7406 - val_accuracy: 0.7011\n",
      "Epoch 86/100\n",
      "1555/1555 [==============================] - 1s 817us/step - loss: 0.7129 - accuracy: 0.6985 - val_loss: 0.7407 - val_accuracy: 0.7010\n",
      "Epoch 87/100\n",
      "1555/1555 [==============================] - 1s 823us/step - loss: 0.7129 - accuracy: 0.6991 - val_loss: 0.7415 - val_accuracy: 0.6972\n",
      "Epoch 88/100\n",
      "1555/1555 [==============================] - 1s 831us/step - loss: 0.7127 - accuracy: 0.6990 - val_loss: 0.7403 - val_accuracy: 0.6959\n",
      "Epoch 89/100\n",
      "1555/1555 [==============================] - 1s 822us/step - loss: 0.7130 - accuracy: 0.6990 - val_loss: 0.7400 - val_accuracy: 0.6984\n",
      "Epoch 90/100\n",
      "1555/1555 [==============================] - 1s 814us/step - loss: 0.7126 - accuracy: 0.6990 - val_loss: 0.7409 - val_accuracy: 0.6956\n",
      "Epoch 91/100\n",
      "1555/1555 [==============================] - 1s 816us/step - loss: 0.7128 - accuracy: 0.6994 - val_loss: 0.7403 - val_accuracy: 0.7013\n",
      "Epoch 92/100\n",
      "1555/1555 [==============================] - 1s 831us/step - loss: 0.7126 - accuracy: 0.6989 - val_loss: 0.7405 - val_accuracy: 0.6959\n",
      "Epoch 93/100\n",
      "1555/1555 [==============================] - 1s 816us/step - loss: 0.7126 - accuracy: 0.6990 - val_loss: 0.7408 - val_accuracy: 0.7018\n",
      "Epoch 94/100\n",
      "1555/1555 [==============================] - 1s 813us/step - loss: 0.7127 - accuracy: 0.6992 - val_loss: 0.7404 - val_accuracy: 0.6958\n",
      "Epoch 95/100\n",
      "1555/1555 [==============================] - 1s 811us/step - loss: 0.7126 - accuracy: 0.6987 - val_loss: 0.7401 - val_accuracy: 0.6980\n",
      "Epoch 96/100\n",
      "1555/1555 [==============================] - 1s 813us/step - loss: 0.7125 - accuracy: 0.6989 - val_loss: 0.7402 - val_accuracy: 0.7042\n",
      "Epoch 97/100\n",
      "1555/1555 [==============================] - 1s 812us/step - loss: 0.7129 - accuracy: 0.6983 - val_loss: 0.7418 - val_accuracy: 0.7003\n",
      "Epoch 98/100\n",
      "1555/1555 [==============================] - 1s 814us/step - loss: 0.7125 - accuracy: 0.6994 - val_loss: 0.7406 - val_accuracy: 0.6951\n",
      "Epoch 99/100\n",
      "1555/1555 [==============================] - 1s 804us/step - loss: 0.7124 - accuracy: 0.6992 - val_loss: 0.7400 - val_accuracy: 0.7020\n",
      "Epoch 100/100\n",
      "1555/1555 [==============================] - 1s 813us/step - loss: 0.7129 - accuracy: 0.6989 - val_loss: 0.7406 - val_accuracy: 0.6942\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mean_squared_error',\n",
    "                    optimizer='adam')\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"autoencoder_fraud.h5\",\n",
    "                               save_best_only=True,\n",
    "                               verbose=0)\n",
    "\n",
    "tb = TensorBoard(log_dir='./logs',\n",
    "                histogram_freq=0,\n",
    "                write_graph=True,\n",
    "                write_images=True)\n",
    "\n",
    "history = autoencoder.fit(train_x, train_x,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(test_x, test_x),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, tb]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = load_model('autoencoder_fraud.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seems like our model work nicely, now we will make the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = autoencoder.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean(np.power(test_x - pred, 2), axis=1)\n",
    "error_df = pd.DataFrame({'Reconstruction_error': mse,\n",
    "                        'True_class': test_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([77.24055566,  0.87190388,  0.24955684, ...,  0.51939849,\n",
       "        0.24887566,  0.1524689 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df.Reconstruction_error.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use a threshold to separate between fraudulent transactions and legitimate transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_fixed = 5\n",
    "pred_y = [1 if e > threshold_fixed else 0 for e in error_df.Reconstruction_error.values]\n",
    "matrix = confusion_matrix(error_df.True_class, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpos = matrix[0][0]\n",
    "fneg = matrix[1][1]\n",
    "fpos = matrix[0][1]\n",
    "tneg = matrix[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.88%\n",
      "Cohen Kappa: 0.162\n",
      "Sensitivity/Recall for Model : 0.69\n",
      "F1 Score for Model : 0.16\n"
     ]
    }
   ],
   "source": [
    "print( 'Accuracy: '+ str(np.round(100*float(tpos+fneg)/float(tpos+fneg + fpos + tneg),2))+'%')\n",
    "print( 'Cohen Kappa: '+ str(np.round(cohen_kappa_score(error_df.True_class, pred_y),3)))\n",
    "print(\"Sensitivity/Recall for Model : {}\".format(round(recall_score(error_df.True_class, pred_y), 2)))\n",
    "print(\"F1 Score for Model : {}\".format(round(f1_score(error_df.True_class, pred_y), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.61084158e-02, -3.22657637e-03, -1.08144388e-01,\n",
       "         -4.09854436e-03, -4.62350920e-02, -5.46136014e-02,\n",
       "          1.20522588e-01, -9.26174968e-03,  2.16852799e-02,\n",
       "         -3.80378366e-02, -8.57327357e-02,  5.54466367e-01,\n",
       "          3.92937213e-02, -2.91230921e-02],\n",
       "        [ 2.49136806e-01, -4.13433695e-03,  5.69025427e-03,\n",
       "          3.56259160e-02,  5.40854074e-02,  8.26913565e-02,\n",
       "         -1.04768828e-01,  3.11835576e-03,  3.99607532e-02,\n",
       "          6.18709140e-02, -7.48284115e-03,  1.87593654e-01,\n",
       "         -3.16006131e-02,  6.46821707e-02],\n",
       "        [-7.53354281e-02,  2.33441498e-02,  3.47066671e-02,\n",
       "         -1.10596135e-01,  2.39842944e-02, -3.38494778e-02,\n",
       "         -1.92254118e-03,  1.40136154e-02, -2.10160371e-02,\n",
       "         -9.98748373e-03, -2.02548690e-02, -1.73908565e-02,\n",
       "         -1.17620751e-02, -2.90368572e-02],\n",
       "        [-2.94110253e-02, -1.73569713e-02,  6.62925914e-02,\n",
       "          2.93771364e-02, -8.28345865e-02,  1.18160494e-01,\n",
       "          1.51864663e-01, -5.86560369e-03, -9.34723914e-02,\n",
       "         -1.80255827e-02, -5.55780292e-01, -1.58144817e-01,\n",
       "         -2.18934547e-02, -4.10056114e-02],\n",
       "        [-5.24415001e-02,  5.56979924e-02, -1.05052099e-01,\n",
       "         -6.59136474e-02,  1.76897258e-01,  5.29803149e-02,\n",
       "         -1.10204682e-01,  5.00764512e-02,  1.50908343e-02,\n",
       "          3.09872162e-02, -2.69556176e-02, -6.50845747e-03,\n",
       "          2.32311990e-02,  1.87757894e-01],\n",
       "        [-2.28347611e-02,  8.40770174e-03,  1.63801089e-01,\n",
       "         -1.01606240e-02, -3.87150533e-02,  1.72412112e-01,\n",
       "          8.69782548e-03, -2.24172752e-02, -1.86928272e-01,\n",
       "         -4.35783118e-02,  1.87311303e-02,  1.50053769e-01,\n",
       "         -2.51980033e-02, -2.21811812e-02],\n",
       "        [-2.55115889e-02, -4.33819778e-02,  1.94645464e-01,\n",
       "         -4.22413368e-03, -2.84621064e-02,  7.04171583e-02,\n",
       "         -5.26958928e-02,  3.31389322e-03,  2.34567337e-02,\n",
       "         -4.70723659e-02, -3.17638777e-02,  9.12458636e-03,\n",
       "         -5.25972784e-01, -3.53856161e-02],\n",
       "        [-5.71265221e-02, -1.76762063e-02,  1.48907704e-02,\n",
       "         -1.96154751e-02,  9.36557353e-02,  3.19858976e-02,\n",
       "          1.59636632e-01,  1.11747012e-02, -7.75821358e-02,\n",
       "         -5.81493368e-03,  4.51259464e-02, -2.07290966e-02,\n",
       "          2.74079069e-02, -3.42940800e-02],\n",
       "        [-6.92241490e-02,  5.68834692e-03, -2.92082205e-02,\n",
       "         -2.24404735e-03,  3.53974365e-02, -9.82077792e-03,\n",
       "         -1.53234422e-01,  3.43250367e-03, -6.02141162e-03,\n",
       "          1.06094638e-02, -8.57857615e-03,  1.33125242e-02,\n",
       "         -1.86975077e-02,  5.28179668e-03],\n",
       "        [ 3.65284771e-01,  3.37742344e-02,  9.97433555e-04,\n",
       "         -8.89434293e-02,  5.73704094e-02,  6.32079780e-01,\n",
       "          1.18136190e-01,  2.91392617e-02,  7.89269805e-03,\n",
       "          8.50327238e-02, -4.74709040e-03,  6.46035373e-02,\n",
       "          5.84446639e-03, -2.46553142e-02],\n",
       "        [ 1.80196598e-01, -1.94839314e-02,  1.78830445e-01,\n",
       "          9.76305455e-02, -6.23645596e-02,  6.74761906e-02,\n",
       "          1.91950008e-01, -3.07355169e-03,  1.07177524e-02,\n",
       "         -4.97717597e-03,  3.67279239e-02,  7.71156996e-02,\n",
       "         -6.26040157e-03,  3.08780535e-03],\n",
       "        [ 1.41922817e-01, -5.40460534e-02, -1.52057290e-01,\n",
       "         -2.18722206e-02,  1.20706670e-01,  1.43787622e-01,\n",
       "         -7.40238726e-01, -3.77969770e-03,  3.66330817e-02,\n",
       "          1.32788224e-02, -2.60540321e-02, -6.55248240e-02,\n",
       "         -6.56171469e-03,  2.79726298e-03],\n",
       "        [-1.42152220e-01, -8.18117615e-03,  2.05682546e-01,\n",
       "         -2.25179754e-02,  2.58967895e-02, -4.72398758e-01,\n",
       "          6.30194880e-03, -9.94250085e-03, -1.50118629e-02,\n",
       "         -1.22511974e-02,  4.43925783e-02,  8.62769410e-02,\n",
       "         -8.07149187e-02, -8.09668377e-03],\n",
       "        [ 3.02676976e-01,  1.85990214e-01,  3.11520677e-02,\n",
       "          1.22006135e-02, -1.49793819e-01,  2.29543597e-01,\n",
       "          3.36621515e-02,  1.44534754e-02,  1.28997108e-02,\n",
       "         -5.37816482e-03,  1.11812260e-02, -1.17084687e-03,\n",
       "          6.86897617e-03, -2.17103772e-02],\n",
       "        [ 5.70333302e-01, -6.59286380e-02,  1.89702317e-01,\n",
       "         -9.71843861e-03, -2.22637966e-01,  4.24086720e-01,\n",
       "          2.31476352e-01,  5.18567786e-02,  1.46061350e-02,\n",
       "         -1.11320741e-01,  6.25731796e-02,  5.07062376e-02,\n",
       "         -1.17404722e-02, -6.97989315e-02],\n",
       "        [-4.04926948e-02,  9.96195525e-03, -6.15403689e-02,\n",
       "         -1.47915808e-02,  4.96724695e-02, -2.98657298e-01,\n",
       "          4.03504185e-02, -1.47529267e-04, -1.56494677e-02,\n",
       "          5.91228865e-02, -2.47005355e-02,  1.10928132e-03,\n",
       "          3.65256295e-02,  5.94467111e-02],\n",
       "        [ 2.35318974e-01, -6.74574077e-02, -7.73505390e-01,\n",
       "          3.05201467e-02, -6.59858733e-02,  2.25245461e-01,\n",
       "          1.71149984e-01, -3.51403444e-03, -1.61672868e-02,\n",
       "         -6.08667992e-02,  2.20276378e-02,  2.66049560e-02,\n",
       "         -2.55193841e-02, -3.54225487e-02],\n",
       "        [ 4.41432387e-01, -8.15893784e-02,  4.24963385e-01,\n",
       "          6.25528991e-02, -1.91223234e-01,  5.73485255e-01,\n",
       "          2.16752589e-01, -4.18913737e-02,  2.26272531e-02,\n",
       "         -1.60063073e-01,  7.51039833e-02, -2.67734169e-03,\n",
       "         -1.96476374e-02, -1.03624880e-01],\n",
       "        [ 1.54703915e-01, -4.53448594e-02, -1.46581143e-01,\n",
       "         -6.85648061e-03, -5.75059131e-02,  1.87885836e-01,\n",
       "          1.11797228e-01, -2.03746874e-02, -7.64574949e-03,\n",
       "         -5.60574420e-02,  3.35331485e-02, -6.46004337e-04,\n",
       "         -3.79275950e-03, -3.82737741e-02],\n",
       "        [-7.78776824e-01,  1.36458939e-02, -1.73941553e-01,\n",
       "          3.93882301e-03, -4.62914221e-02, -1.01540983e-01,\n",
       "          1.11334836e-02,  1.78251360e-02, -3.37613150e-02,\n",
       "          3.03830225e-02,  2.02514045e-02, -7.00529739e-02,\n",
       "         -1.27248717e-02,  4.34619822e-02],\n",
       "        [ 6.74059689e-02,  7.62678981e-02, -4.35814500e-01,\n",
       "         -2.55885106e-02,  7.11989254e-02,  4.75503840e-02,\n",
       "          8.41907412e-02,  3.45768756e-03, -3.89238559e-02,\n",
       "          4.33822460e-02, -1.12042800e-02, -1.13026954e-01,\n",
       "          6.54180050e-02, -3.49435955e-02],\n",
       "        [-2.40505952e-02,  8.10423587e-03, -2.88865894e-01,\n",
       "         -5.24081662e-03,  1.62812173e-02, -4.07275036e-02,\n",
       "         -3.59597169e-02,  3.15904729e-02, -1.33841382e-02,\n",
       "          1.76853761e-02,  6.96399016e-03, -5.53726852e-02,\n",
       "          1.56581625e-02, -8.34999513e-03],\n",
       "        [-1.87266544e-01, -7.67093105e-03, -3.70294094e-01,\n",
       "          2.12182868e-02, -3.57794799e-02, -1.26024142e-01,\n",
       "          6.04671799e-02, -2.71599228e-03, -7.83915352e-03,\n",
       "         -9.21056885e-03,  3.92717607e-02, -1.25147135e-03,\n",
       "         -2.08029356e-02, -2.29221256e-03],\n",
       "        [ 3.80699448e-02,  1.37380594e-02,  9.40406397e-02,\n",
       "          3.33777233e-03, -1.92650054e-02,  1.07598770e-02,\n",
       "         -4.41034660e-02,  5.99486660e-03,  1.21123027e-02,\n",
       "         -1.53528126e-02, -5.87012619e-03,  3.09373327e-02,\n",
       "          2.34349687e-02, -1.02635501e-02],\n",
       "        [-4.77239899e-02, -2.68358435e-03,  4.85138893e-02,\n",
       "         -1.11167575e-03,  3.63068725e-03, -1.06732771e-02,\n",
       "         -2.53717899e-02, -1.08807636e-02,  2.91999485e-02,\n",
       "         -3.48532200e-02, -2.99111288e-02,  6.51021600e-02,\n",
       "          3.02630235e-02, -1.73553955e-02],\n",
       "        [ 2.65688866e-01,  2.52790861e-02,  6.95467554e-03,\n",
       "          2.15220675e-02,  1.00994080e-01,  3.50092016e-02,\n",
       "         -1.18538752e-01, -3.55341681e-03,  3.00342645e-02,\n",
       "          7.95438141e-02, -4.26179059e-02,  9.57595259e-02,\n",
       "         -5.72840916e-03,  5.43172732e-02],\n",
       "        [ 5.72993979e-02, -6.75522722e-03,  7.28446841e-02,\n",
       "         -5.03385440e-02,  2.10316069e-02, -1.00368131e-02,\n",
       "         -1.08472630e-02,  1.92504749e-02, -1.36208367e-02,\n",
       "         -5.95268747e-03,  2.11289320e-02,  3.21002714e-02,\n",
       "         -8.24269187e-03,  8.24011303e-03],\n",
       "        [-1.36391163e-01, -2.58201994e-02,  2.64491905e-02,\n",
       "         -8.99032410e-03,  4.20613326e-02, -1.91558488e-02,\n",
       "         -6.31400198e-02, -1.22798551e-02, -1.43654840e-02,\n",
       "          1.42159723e-02, -2.60417368e-02,  2.54956465e-02,\n",
       "         -5.35688363e-02,  2.27467017e-03],\n",
       "        [-7.42511973e-02,  3.60977347e-03, -8.84900764e-02,\n",
       "          1.11950208e-02, -2.55843857e-03, -6.66320473e-02,\n",
       "          4.35908027e-02,  1.61426347e-02,  1.47328619e-02,\n",
       "         -5.94660500e-03,  1.06514315e-03,  1.99138392e-02,\n",
       "          8.33606645e-02,  1.90139432e-02],\n",
       "        [ 9.49831009e-02,  4.64780107e-02,  2.52149075e-01,\n",
       "          4.40630801e-02,  6.78771213e-02,  1.44456446e-01,\n",
       "          4.64697838e-01,  5.48737943e-02,  3.93370613e-02,\n",
       "         -7.42267221e-02, -2.06027329e-02, -9.62422881e-03,\n",
       "          1.46060288e-02, -4.59755100e-02]], dtype=float32),\n",
       " array([ 1.6577715 , -0.43705738,  1.1667398 ,  0.05768   ,  0.07237738,\n",
       "         0.10317028,  0.77659357, -1.8855014 ,  1.2277699 , -0.3844056 ,\n",
       "         0.88819176, -0.9082783 ,  1.2554371 , -0.4715001 ], dtype=float32),\n",
       " array([[ 1.14434578e-01, -1.45048294e-02,  3.99972722e-02,\n",
       "          3.45888883e-02,  4.09183979e-01,  4.61556256e-01,\n",
       "          7.02604130e-02],\n",
       "        [ 1.48091882e-01,  1.20013535e-01,  1.06609955e-01,\n",
       "          2.06933301e-02,  4.33079302e-01,  3.30954850e-01,\n",
       "          8.00252780e-02],\n",
       "        [ 2.37634256e-02, -6.06072769e-02, -2.22932026e-02,\n",
       "          2.51225829e-01, -4.23331186e-03,  2.90723555e-02,\n",
       "          1.50922611e-02],\n",
       "        [ 4.86116916e-01, -4.03832823e-01, -4.01815444e-01,\n",
       "          1.33351177e-01,  9.21469927e-01, -2.40001097e-01,\n",
       "          5.14849126e-01],\n",
       "        [ 6.20558336e-02,  1.78971216e-01,  3.89516674e-04,\n",
       "         -1.36225000e-01,  9.91665758e-03,  2.26819310e-02,\n",
       "          1.43930003e-01],\n",
       "        [ 1.86764136e-01,  9.32034180e-02,  7.62571022e-02,\n",
       "          1.02187328e-01,  6.32040977e-01,  4.78474110e-01,\n",
       "          6.90452233e-02],\n",
       "        [ 9.46514904e-02,  6.87749609e-02, -1.98993236e-02,\n",
       "         -1.02031544e-01,  3.66269387e-02,  3.32264081e-02,\n",
       "          1.80630520e-01],\n",
       "        [ 6.23973131e-01, -1.94516391e-01,  6.03836179e-01,\n",
       "          5.21450937e-01, -3.57842088e-01,  2.40422577e-01,\n",
       "          1.11664951e+00],\n",
       "        [-6.78385496e-02, -1.09872854e+00, -4.71133925e-02,\n",
       "         -1.71712935e-01, -3.92214477e-01,  2.41239682e-01,\n",
       "          7.34304488e-02],\n",
       "        [ 3.36670503e-02, -1.91105902e-01, -4.37996149e-01,\n",
       "          1.71522517e-02, -1.48867294e-01,  1.93033174e-01,\n",
       "          1.74582526e-02],\n",
       "        [-1.99681178e-01,  1.92348510e-02, -5.65756857e-03,\n",
       "         -2.54507754e-02,  1.40227839e-01,  9.74607468e-02,\n",
       "          8.93522874e-02],\n",
       "        [-2.15898842e-01,  6.28379509e-02, -3.10144806e-03,\n",
       "         -1.16275959e-02,  1.60773352e-01,  1.05441295e-01,\n",
       "          8.49016309e-02],\n",
       "        [-4.61023673e-02,  9.66945589e-02,  1.94848124e-02,\n",
       "         -4.61098939e-01, -1.04353711e-01, -1.31044000e-01,\n",
       "         -4.71182577e-02],\n",
       "        [-2.93054849e-01, -4.62156504e-01,  6.11492038e-01,\n",
       "         -2.57785656e-02, -3.53926927e-01, -2.30709940e-01,\n",
       "         -2.67847121e-01]], dtype=float32),\n",
       " array([0.97730047, 1.0137357 , 1.1752223 , 1.1776463 , 0.77759147,\n",
       "        0.9899457 , 1.1892897 ], dtype=float32),\n",
       " array([[ 0.42967445,  0.27942833,  0.17278151, -0.34271136,  0.23137255,\n",
       "          0.04478044,  0.7907621 ],\n",
       "        [-0.68585855,  0.6210502 , -0.14745054, -0.63162535,  0.31091025,\n",
       "          0.23880257, -0.28988186],\n",
       "        [ 0.0625108 , -0.64553076, -0.7735958 , -0.11039491,  0.39948964,\n",
       "          0.18162553,  0.2664176 ],\n",
       "        [-0.4169136 ,  0.19652234, -0.35212353, -0.23662345, -0.09338817,\n",
       "         -0.9422495 , -0.01163083],\n",
       "        [ 0.10291126, -0.37573564, -0.18263122, -0.00794486, -0.77083606,\n",
       "          0.36108068,  0.16409679],\n",
       "        [ 0.7098674 ,  0.4113078 , -0.04042158,  0.0993399 ,  0.30461228,\n",
       "         -0.32318386, -0.49312952],\n",
       "        [-0.4603387 ,  0.6182571 , -0.3452606 ,  0.90881926,  0.5967977 ,\n",
       "          0.21276201,  0.07936551]], dtype=float32),\n",
       " array([-0.60198843, -0.93363446,  1.0137461 ,  0.14570232, -0.10336649,\n",
       "        -0.01098909, -0.08081039], dtype=float32),\n",
       " array([[-1.89759481e+00,  3.29095936e+00,  2.10556364e+00,\n",
       "          2.09490800e+00,  1.75665930e-01, -4.13415575e+00,\n",
       "         -1.69285905e+00, -4.80660915e+00, -5.93765020e-01,\n",
       "          4.60151148e+00, -1.18021250e+00,  9.35427368e-01,\n",
       "          5.58495820e-01,  1.07918167e+01, -7.86005080e-01,\n",
       "          1.32774889e+00,  1.61393988e+00,  8.72687697e-01,\n",
       "          1.52922535e+00, -5.83603954e+00,  2.12972260e+00,\n",
       "          1.40815362e-01, -7.19523609e-01, -2.36042198e-02,\n",
       "          1.07605481e+00,  1.17214048e+00, -7.19525695e-01,\n",
       "         -3.84609371e-01, -3.06129575e-01, -1.29553556e+00],\n",
       "        [ 2.39440560e-01, -2.73912406e+00,  2.47401232e-03,\n",
       "          2.91819006e-01, -4.73788929e+00, -1.66693702e-01,\n",
       "          2.13801217e+00,  6.19187069e+00, -3.14616561e-02,\n",
       "          3.75624394e+00, -3.45497441e+00, -3.13820887e+00,\n",
       "         -9.19424772e-01,  2.31275129e+00, -1.02985942e+00,\n",
       "         -7.09558725e-01, -1.76751959e+00, -3.34689832e+00,\n",
       "         -2.16138029e+00, -5.92679501e-01,  4.94292402e+00,\n",
       "          2.26892859e-01, -1.37316191e+00, -1.89884137e-02,\n",
       "         -3.03614944e-01, -2.42938265e-01, -6.97799504e-01,\n",
       "          2.07269788e+00, -1.60205162e+00,  6.18515921e+00],\n",
       "        [-6.01577401e-01,  2.04976988e+00, -2.03393149e+00,\n",
       "          2.61110926e+00, -6.14099741e+00, -4.52380991e+00,\n",
       "         -3.88531280e+00, -3.18013859e+00,  7.28245527e-02,\n",
       "          2.68326092e+00, -1.15708005e+00,  4.27413654e+00,\n",
       "          3.67350149e+00, -5.52122307e+00,  2.75323129e+00,\n",
       "          4.95339537e+00,  2.44619584e+00, -1.27365565e+00,\n",
       "          1.55368054e+00,  1.72736764e+00, -2.00440383e+00,\n",
       "         -1.14370123e-01,  2.88997173e+00,  2.88613677e-01,\n",
       "          1.88133776e+00,  1.11682653e+00, -3.37281942e-01,\n",
       "          3.50763470e-01, -3.19553129e-02, -6.51916456e+00],\n",
       "        [ 1.67652655e+00,  4.57505655e+00, -4.56902552e+00,\n",
       "         -4.06327915e+00, -2.48314738e-01, -2.90045619e+00,\n",
       "          1.96432173e+00,  5.01517534e+00, -6.03152215e-01,\n",
       "          3.91621113e-01,  1.89140034e+00, -3.92628217e+00,\n",
       "          4.98096138e-01, -5.22234583e+00,  2.00389791e+00,\n",
       "          2.74114919e+00, -1.43126154e+00, -5.72602034e+00,\n",
       "         -2.88530564e+00, -5.46534300e-01,  6.35084629e-01,\n",
       "          4.25948590e-01,  1.27370346e+00, -8.08452535e-03,\n",
       "         -1.25010699e-01,  3.57908458e-01, -9.95800924e-03,\n",
       "          2.00376105e+00,  1.47033966e+00,  6.41028023e+00],\n",
       "        [-1.12348878e+00, -4.19613898e-01,  8.24413586e+00,\n",
       "          1.73278928e+00,  3.94920874e+00, -4.23787212e+00,\n",
       "          1.48090613e+00,  6.60331726e+00, -1.98310542e+00,\n",
       "          4.77958262e-01, -6.96601689e-01, -4.26760626e+00,\n",
       "          7.75061548e-01, -4.45164680e+00,  2.72905684e+00,\n",
       "          4.39595032e+00, -5.90555072e-01,  6.98944926e-01,\n",
       "          3.73182774e-01,  7.53803611e-01,  2.17137361e+00,\n",
       "          7.99205959e-01,  1.19988167e+00, -1.09758444e-01,\n",
       "          1.44178951e+00,  8.80882740e-01,  3.48774344e-01,\n",
       "          1.88643670e+00,  8.99606764e-01,  6.38539553e+00],\n",
       "        [ 1.22317123e+00, -1.98696852e+00, -1.04363072e+00,\n",
       "         -6.00622118e-01,  7.52703488e-01,  1.88481939e+00,\n",
       "         -4.81701708e+00,  1.42401159e+00, -8.87950718e-01,\n",
       "         -9.90996301e-01, -2.26552695e-01, -2.16791883e-01,\n",
       "         -2.33415556e+00,  2.14733529e+00, -2.93745303e+00,\n",
       "         -8.40413094e-01,  3.28581071e+00,  4.63297069e-01,\n",
       "          3.28633022e+00, -4.76076156e-01,  6.27314520e+00,\n",
       "          2.10962033e+00,  3.21498919e+00, -5.46740368e-02,\n",
       "         -3.58687967e-01, -6.89436495e-01, -7.43549019e-02,\n",
       "         -6.65624499e-01,  4.83388424e-01,  1.82374048e+00],\n",
       "        [-2.40195107e+00, -3.12928987e+00, -5.81518221e+00,\n",
       "          4.60849905e+00,  3.16056228e+00, -1.17109084e+00,\n",
       "          2.14689159e+00,  2.96165347e+00, -2.53182322e-01,\n",
       "         -3.05735970e+00,  1.64971542e+00, -2.93575168e+00,\n",
       "         -3.05466270e+00, -1.40185297e+00, -3.44903779e+00,\n",
       "          1.15273967e-02, -6.70151055e-01, -5.65111923e+00,\n",
       "         -2.39601755e+00,  1.34636331e+00,  8.80319178e-01,\n",
       "          3.95027369e-01, -1.46393585e+00,  1.28257675e-02,\n",
       "          6.30947769e-01,  2.25414768e-01,  4.53816682e-01,\n",
       "         -1.83746278e+00,  1.16536522e+00,  6.84716320e+00]], dtype=float32),\n",
       " array([-0.06557652, -1.1466552 , -1.2481561 , -0.20752814, -0.3446722 ,\n",
       "         0.15887389,  1.3857981 ,  0.5250913 , -0.49451998,  0.8952484 ,\n",
       "        -1.2254747 , -1.8381451 , -1.2395184 , -3.7596693 , -1.966307  ,\n",
       "        -1.7473876 , -1.1453398 , -2.936331  , -1.6970296 , -3.0301604 ,\n",
       "        -0.32206178, -0.38785255, -2.1052547 , -0.35172287, -0.7254543 ,\n",
       "        -0.30914158, -0.70691824, -0.82003564, -1.5356148 ,  1.6598207 ],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = autoencoder.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
