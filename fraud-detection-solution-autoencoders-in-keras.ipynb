{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('creditcard.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n",
      "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
      "       'Class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31 columns, 2 of which are Time and Amount. The rest are output from the PCA transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not Fraud    284315\n",
       "Fraud           492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Class.value_counts().rename(index = {0:'Not Fraud', 1:'Fraud'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 285k transactions just 492 were labelled as fraudulent, it is a small percentage but may represent billions of dollars of lost revenue each year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PCA done on the dataset transformed it into standard-normal form. I will do the same to the 'time' and 'amount' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Time'] = StandardScaler().fit_transform(data['Time'].values.reshape(-1, 1))\n",
    "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data into training and testing sets, And To evaluate the performance of our model we will training our model on the legitimate transactions,only, And Reserving the correct class on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = train_test_split(data,test_size = 0.3,random_state=42)\n",
    "train_x = train_x[train_x.Class == 0] \n",
    "train_x = train_x.drop(['Class'], axis=1) \n",
    "\n",
    "\n",
    "test_y = test_x['Class']\n",
    "test_x = test_x.drop(['Class'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Autoencoder uses 4 Desnse (fully connected) layers with 14, 7, 7 and 30 neurons respectively. The first two layers are used for our encoder, the last two go for the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_x.shape[1]\n",
    "encoding_dim = int(input_dim / 2) - 1\n",
    "hidden_dim = int(encoding_dim / 2)\n",
    "learning_rate = 1e-7\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
    "decoder = Dense(hidden_dim, activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train our model for 100 epochs with a batch size of 128 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 100\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Model Checkpoint to save the best model and TensorBoard for graph visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/1555 [..............................] - ETA: 0s - loss: 1.0315 - accuracy: 0.0312WARNING:tensorflow:From /Users/sahebsingh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0012s vs `on_train_batch_end` time: 0.0294s). Check your callbacks.\n",
      "1555/1555 [==============================] - 2s 1ms/step - loss: 0.8794 - accuracy: 0.4840 - val_loss: 0.8385 - val_accuracy: 0.5635\n",
      "Epoch 2/100\n",
      "1555/1555 [==============================] - 2s 1ms/step - loss: 0.7962 - accuracy: 0.5805 - val_loss: 0.8004 - val_accuracy: 0.5956\n",
      "Epoch 3/100\n",
      "1555/1555 [==============================] - 2s 1ms/step - loss: 0.7717 - accuracy: 0.6020 - val_loss: 0.7870 - val_accuracy: 0.6072\n",
      "Epoch 4/100\n",
      "1555/1555 [==============================] - 1s 911us/step - loss: 0.7604 - accuracy: 0.6088 - val_loss: 0.7784 - val_accuracy: 0.6083\n",
      "Epoch 5/100\n",
      "1555/1555 [==============================] - 1s 893us/step - loss: 0.7520 - accuracy: 0.6083 - val_loss: 0.7703 - val_accuracy: 0.6155\n",
      "Epoch 6/100\n",
      "1555/1555 [==============================] - 1s 910us/step - loss: 0.7422 - accuracy: 0.6093 - val_loss: 0.7598 - val_accuracy: 0.6140\n",
      "Epoch 7/100\n",
      "1555/1555 [==============================] - 1s 906us/step - loss: 0.7357 - accuracy: 0.6135 - val_loss: 0.7548 - val_accuracy: 0.6161\n",
      "Epoch 8/100\n",
      "1555/1555 [==============================] - 1s 901us/step - loss: 0.7319 - accuracy: 0.6174 - val_loss: 0.7513 - val_accuracy: 0.6208\n",
      "Epoch 9/100\n",
      "1555/1555 [==============================] - 1s 900us/step - loss: 0.7295 - accuracy: 0.6204 - val_loss: 0.7491 - val_accuracy: 0.6198\n",
      "Epoch 10/100\n",
      "1555/1555 [==============================] - 1s 893us/step - loss: 0.7274 - accuracy: 0.6210 - val_loss: 0.7477 - val_accuracy: 0.6225\n",
      "Epoch 11/100\n",
      "1555/1555 [==============================] - 1s 889us/step - loss: 0.7261 - accuracy: 0.6200 - val_loss: 0.7475 - val_accuracy: 0.6190\n",
      "Epoch 12/100\n",
      "1555/1555 [==============================] - 1s 884us/step - loss: 0.7252 - accuracy: 0.6199 - val_loss: 0.7456 - val_accuracy: 0.6231\n",
      "Epoch 13/100\n",
      "1555/1555 [==============================] - 1s 894us/step - loss: 0.7240 - accuracy: 0.6201 - val_loss: 0.7446 - val_accuracy: 0.6236\n",
      "Epoch 14/100\n",
      "1555/1555 [==============================] - 1s 880us/step - loss: 0.7227 - accuracy: 0.6218 - val_loss: 0.7446 - val_accuracy: 0.6257\n",
      "Epoch 15/100\n",
      "1555/1555 [==============================] - 1s 921us/step - loss: 0.7220 - accuracy: 0.6228 - val_loss: 0.7431 - val_accuracy: 0.6238\n",
      "Epoch 16/100\n",
      "1555/1555 [==============================] - 1s 921us/step - loss: 0.7214 - accuracy: 0.6228 - val_loss: 0.7427 - val_accuracy: 0.6257\n",
      "Epoch 17/100\n",
      "1555/1555 [==============================] - 1s 892us/step - loss: 0.7207 - accuracy: 0.6238 - val_loss: 0.7427 - val_accuracy: 0.6249\n",
      "Epoch 18/100\n",
      "1555/1555 [==============================] - 1s 899us/step - loss: 0.7201 - accuracy: 0.6260 - val_loss: 0.7416 - val_accuracy: 0.6298\n",
      "Epoch 19/100\n",
      "1555/1555 [==============================] - 1s 910us/step - loss: 0.7199 - accuracy: 0.6272 - val_loss: 0.7418 - val_accuracy: 0.6278\n",
      "Epoch 20/100\n",
      "1555/1555 [==============================] - 1s 924us/step - loss: 0.7191 - accuracy: 0.6297 - val_loss: 0.7411 - val_accuracy: 0.6290\n",
      "Epoch 21/100\n",
      "1555/1555 [==============================] - 1s 905us/step - loss: 0.7183 - accuracy: 0.6303 - val_loss: 0.7407 - val_accuracy: 0.6359\n",
      "Epoch 22/100\n",
      "1555/1555 [==============================] - 1s 902us/step - loss: 0.7175 - accuracy: 0.6321 - val_loss: 0.7403 - val_accuracy: 0.6346\n",
      "Epoch 23/100\n",
      "1555/1555 [==============================] - 1s 894us/step - loss: 0.7170 - accuracy: 0.6333 - val_loss: 0.7396 - val_accuracy: 0.6348\n",
      "Epoch 24/100\n",
      "1555/1555 [==============================] - 1s 893us/step - loss: 0.7164 - accuracy: 0.6342 - val_loss: 0.7394 - val_accuracy: 0.6336\n",
      "Epoch 25/100\n",
      "1555/1555 [==============================] - 1s 896us/step - loss: 0.7160 - accuracy: 0.6352 - val_loss: 0.7390 - val_accuracy: 0.6347\n",
      "Epoch 26/100\n",
      "1555/1555 [==============================] - 1s 877us/step - loss: 0.7156 - accuracy: 0.6361 - val_loss: 0.7392 - val_accuracy: 0.6395\n",
      "Epoch 27/100\n",
      "1555/1555 [==============================] - 1s 867us/step - loss: 0.7151 - accuracy: 0.6366 - val_loss: 0.7397 - val_accuracy: 0.6381\n",
      "Epoch 28/100\n",
      "1555/1555 [==============================] - 1s 890us/step - loss: 0.7151 - accuracy: 0.6368 - val_loss: 0.7383 - val_accuracy: 0.6383\n",
      "Epoch 29/100\n",
      "1555/1555 [==============================] - 1s 885us/step - loss: 0.7145 - accuracy: 0.6374 - val_loss: 0.7374 - val_accuracy: 0.6354\n",
      "Epoch 30/100\n",
      "1555/1555 [==============================] - 1s 885us/step - loss: 0.7142 - accuracy: 0.6375 - val_loss: 0.7374 - val_accuracy: 0.6396\n",
      "Epoch 31/100\n",
      "1555/1555 [==============================] - 1s 875us/step - loss: 0.7138 - accuracy: 0.6376 - val_loss: 0.7384 - val_accuracy: 0.6421\n",
      "Epoch 32/100\n",
      "1555/1555 [==============================] - 1s 892us/step - loss: 0.7135 - accuracy: 0.6374 - val_loss: 0.7366 - val_accuracy: 0.6364\n",
      "Epoch 33/100\n",
      "1555/1555 [==============================] - 1s 876us/step - loss: 0.7131 - accuracy: 0.6370 - val_loss: 0.7369 - val_accuracy: 0.6371\n",
      "Epoch 34/100\n",
      "1555/1555 [==============================] - 1s 864us/step - loss: 0.7130 - accuracy: 0.6371 - val_loss: 0.7377 - val_accuracy: 0.6380\n",
      "Epoch 35/100\n",
      "1555/1555 [==============================] - 1s 893us/step - loss: 0.7127 - accuracy: 0.6374 - val_loss: 0.7365 - val_accuracy: 0.6353\n",
      "Epoch 36/100\n",
      "1555/1555 [==============================] - 1s 883us/step - loss: 0.7124 - accuracy: 0.6369 - val_loss: 0.7381 - val_accuracy: 0.6345\n",
      "Epoch 37/100\n",
      "1555/1555 [==============================] - 1s 872us/step - loss: 0.7123 - accuracy: 0.6372 - val_loss: 0.7366 - val_accuracy: 0.6301\n",
      "Epoch 38/100\n",
      "1555/1555 [==============================] - 1s 880us/step - loss: 0.7120 - accuracy: 0.6371 - val_loss: 0.7354 - val_accuracy: 0.6379\n",
      "Epoch 39/100\n",
      "1555/1555 [==============================] - 1s 870us/step - loss: 0.7118 - accuracy: 0.6376 - val_loss: 0.7369 - val_accuracy: 0.6323\n",
      "Epoch 40/100\n",
      "1555/1555 [==============================] - 1s 863us/step - loss: 0.7117 - accuracy: 0.6375 - val_loss: 0.7359 - val_accuracy: 0.6397\n",
      "Epoch 41/100\n",
      "1555/1555 [==============================] - 1s 928us/step - loss: 0.7115 - accuracy: 0.6377 - val_loss: 0.7358 - val_accuracy: 0.6366\n",
      "Epoch 42/100\n",
      "1555/1555 [==============================] - 1s 880us/step - loss: 0.7114 - accuracy: 0.6385 - val_loss: 0.7361 - val_accuracy: 0.6352\n",
      "Epoch 43/100\n",
      "1555/1555 [==============================] - 1s 890us/step - loss: 0.7113 - accuracy: 0.6379 - val_loss: 0.7364 - val_accuracy: 0.6373\n",
      "Epoch 44/100\n",
      "1555/1555 [==============================] - 1s 925us/step - loss: 0.7113 - accuracy: 0.6378 - val_loss: 0.7359 - val_accuracy: 0.6355\n",
      "Epoch 45/100\n",
      "1555/1555 [==============================] - 1s 875us/step - loss: 0.7113 - accuracy: 0.6386 - val_loss: 0.7371 - val_accuracy: 0.6367\n",
      "Epoch 46/100\n",
      "1555/1555 [==============================] - 1s 873us/step - loss: 0.7110 - accuracy: 0.6395 - val_loss: 0.7358 - val_accuracy: 0.6342\n",
      "Epoch 47/100\n",
      "1555/1555 [==============================] - 1s 908us/step - loss: 0.7108 - accuracy: 0.6395 - val_loss: 0.7353 - val_accuracy: 0.6429\n",
      "Epoch 48/100\n",
      "1555/1555 [==============================] - 1s 889us/step - loss: 0.7106 - accuracy: 0.6385 - val_loss: 0.7351 - val_accuracy: 0.6433\n",
      "Epoch 49/100\n",
      "1555/1555 [==============================] - 1s 884us/step - loss: 0.7108 - accuracy: 0.6394 - val_loss: 0.7366 - val_accuracy: 0.6406\n",
      "Epoch 50/100\n",
      "1555/1555 [==============================] - 1s 900us/step - loss: 0.7104 - accuracy: 0.6396 - val_loss: 0.7349 - val_accuracy: 0.6432\n",
      "Epoch 51/100\n",
      "1555/1555 [==============================] - 1s 889us/step - loss: 0.7104 - accuracy: 0.6398 - val_loss: 0.7351 - val_accuracy: 0.6427\n",
      "Epoch 52/100\n",
      "1555/1555 [==============================] - 1s 887us/step - loss: 0.7105 - accuracy: 0.6398 - val_loss: 0.7350 - val_accuracy: 0.6439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "1555/1555 [==============================] - 1s 899us/step - loss: 0.7102 - accuracy: 0.6400 - val_loss: 0.7349 - val_accuracy: 0.6425\n",
      "Epoch 54/100\n",
      "1555/1555 [==============================] - 1s 882us/step - loss: 0.7100 - accuracy: 0.6398 - val_loss: 0.7343 - val_accuracy: 0.6413\n",
      "Epoch 55/100\n",
      "1555/1555 [==============================] - 1s 862us/step - loss: 0.7102 - accuracy: 0.6402 - val_loss: 0.7356 - val_accuracy: 0.6402\n",
      "Epoch 56/100\n",
      "1555/1555 [==============================] - 1s 867us/step - loss: 0.7103 - accuracy: 0.6402 - val_loss: 0.7349 - val_accuracy: 0.6471\n",
      "Epoch 57/100\n",
      "1555/1555 [==============================] - 1s 850us/step - loss: 0.7102 - accuracy: 0.6410 - val_loss: 0.7345 - val_accuracy: 0.6430\n",
      "Epoch 58/100\n",
      "1555/1555 [==============================] - 1s 850us/step - loss: 0.7098 - accuracy: 0.6411 - val_loss: 0.7348 - val_accuracy: 0.6482\n",
      "Epoch 59/100\n",
      "1555/1555 [==============================] - 1s 892us/step - loss: 0.7096 - accuracy: 0.6418 - val_loss: 0.7341 - val_accuracy: 0.6423\n",
      "Epoch 60/100\n",
      "1555/1555 [==============================] - 1s 854us/step - loss: 0.7096 - accuracy: 0.6412 - val_loss: 0.7347 - val_accuracy: 0.6427\n",
      "Epoch 61/100\n",
      "1555/1555 [==============================] - 1s 863us/step - loss: 0.7096 - accuracy: 0.6424 - val_loss: 0.7347 - val_accuracy: 0.6432\n",
      "Epoch 62/100\n",
      "1555/1555 [==============================] - 1s 860us/step - loss: 0.7096 - accuracy: 0.6419 - val_loss: 0.7346 - val_accuracy: 0.6447\n",
      "Epoch 63/100\n",
      "1555/1555 [==============================] - 1s 848us/step - loss: 0.7096 - accuracy: 0.6418 - val_loss: 0.7342 - val_accuracy: 0.6469\n",
      "Epoch 64/100\n",
      "1555/1555 [==============================] - 1s 863us/step - loss: 0.7094 - accuracy: 0.6431 - val_loss: 0.7340 - val_accuracy: 0.6437\n",
      "Epoch 65/100\n",
      "1555/1555 [==============================] - 1s 853us/step - loss: 0.7100 - accuracy: 0.6431 - val_loss: 0.7357 - val_accuracy: 0.6443\n",
      "Epoch 66/100\n",
      "1555/1555 [==============================] - 1s 857us/step - loss: 0.7092 - accuracy: 0.6440 - val_loss: 0.7338 - val_accuracy: 0.6452\n",
      "Epoch 67/100\n",
      "1555/1555 [==============================] - 1s 857us/step - loss: 0.7094 - accuracy: 0.6435 - val_loss: 0.7484 - val_accuracy: 0.6444\n",
      "Epoch 68/100\n",
      "1555/1555 [==============================] - 1s 853us/step - loss: 0.7093 - accuracy: 0.6437 - val_loss: 0.7346 - val_accuracy: 0.6486\n",
      "Epoch 69/100\n",
      "1555/1555 [==============================] - 1s 855us/step - loss: 0.7098 - accuracy: 0.6433 - val_loss: 0.7341 - val_accuracy: 0.6476\n",
      "Epoch 70/100\n",
      "1555/1555 [==============================] - 1s 879us/step - loss: 0.7089 - accuracy: 0.6445 - val_loss: 0.7337 - val_accuracy: 0.6476\n",
      "Epoch 71/100\n",
      "1555/1555 [==============================] - 1s 848us/step - loss: 0.7089 - accuracy: 0.6436 - val_loss: 0.7339 - val_accuracy: 0.6451\n",
      "Epoch 72/100\n",
      "1555/1555 [==============================] - 1s 843us/step - loss: 0.7090 - accuracy: 0.6447 - val_loss: 0.7349 - val_accuracy: 0.6451\n",
      "Epoch 73/100\n",
      "1555/1555 [==============================] - 1s 848us/step - loss: 0.7090 - accuracy: 0.6440 - val_loss: 0.7342 - val_accuracy: 0.6450\n",
      "Epoch 74/100\n",
      "1555/1555 [==============================] - 1s 843us/step - loss: 0.7091 - accuracy: 0.6439 - val_loss: 0.7340 - val_accuracy: 0.6454\n",
      "Epoch 75/100\n",
      "1555/1555 [==============================] - 1s 863us/step - loss: 0.7091 - accuracy: 0.6436 - val_loss: 0.7335 - val_accuracy: 0.6478\n",
      "Epoch 76/100\n",
      "1555/1555 [==============================] - 1s 846us/step - loss: 0.7088 - accuracy: 0.6438 - val_loss: 0.7335 - val_accuracy: 0.6467\n",
      "Epoch 77/100\n",
      "1555/1555 [==============================] - 1s 850us/step - loss: 0.7089 - accuracy: 0.6438 - val_loss: 0.7371 - val_accuracy: 0.6394\n",
      "Epoch 78/100\n",
      "1555/1555 [==============================] - 1s 849us/step - loss: 0.7090 - accuracy: 0.6436 - val_loss: 0.7343 - val_accuracy: 0.6448\n",
      "Epoch 79/100\n",
      "1555/1555 [==============================] - 1s 840us/step - loss: 0.7088 - accuracy: 0.6436 - val_loss: 0.7343 - val_accuracy: 0.6465\n",
      "Epoch 80/100\n",
      "1555/1555 [==============================] - 1s 844us/step - loss: 0.7088 - accuracy: 0.6440 - val_loss: 0.7347 - val_accuracy: 0.6453\n",
      "Epoch 81/100\n",
      "1555/1555 [==============================] - 1s 840us/step - loss: 0.7089 - accuracy: 0.6437 - val_loss: 0.7343 - val_accuracy: 0.6484\n",
      "Epoch 82/100\n",
      "1555/1555 [==============================] - 1s 843us/step - loss: 0.7087 - accuracy: 0.6442 - val_loss: 0.7337 - val_accuracy: 0.6457\n",
      "Epoch 83/100\n",
      "1555/1555 [==============================] - 1s 860us/step - loss: 0.7084 - accuracy: 0.6447 - val_loss: 0.7334 - val_accuracy: 0.6480\n",
      "Epoch 84/100\n",
      "1555/1555 [==============================] - 1s 864us/step - loss: 0.7082 - accuracy: 0.6437 - val_loss: 0.7341 - val_accuracy: 0.6500\n",
      "Epoch 85/100\n",
      "1555/1555 [==============================] - 1s 845us/step - loss: 0.7089 - accuracy: 0.6437 - val_loss: 0.7335 - val_accuracy: 0.6462\n",
      "Epoch 86/100\n",
      "1555/1555 [==============================] - 1s 876us/step - loss: 0.7080 - accuracy: 0.6443 - val_loss: 0.7335 - val_accuracy: 0.6472\n",
      "Epoch 87/100\n",
      "1555/1555 [==============================] - 1s 868us/step - loss: 0.7084 - accuracy: 0.6445 - val_loss: 0.7338 - val_accuracy: 0.6426\n",
      "Epoch 88/100\n",
      "1555/1555 [==============================] - 1s 863us/step - loss: 0.7089 - accuracy: 0.6437 - val_loss: 0.7341 - val_accuracy: 0.6461\n",
      "Epoch 89/100\n",
      "1555/1555 [==============================] - 1s 886us/step - loss: 0.7080 - accuracy: 0.6448 - val_loss: 0.7328 - val_accuracy: 0.6487\n",
      "Epoch 90/100\n",
      "1555/1555 [==============================] - 1s 889us/step - loss: 0.7080 - accuracy: 0.6450 - val_loss: 0.7371 - val_accuracy: 0.6457\n",
      "Epoch 91/100\n",
      "1555/1555 [==============================] - 1s 861us/step - loss: 0.7087 - accuracy: 0.6444 - val_loss: 0.7353 - val_accuracy: 0.6490\n",
      "Epoch 92/100\n",
      "1555/1555 [==============================] - 1s 872us/step - loss: 0.7084 - accuracy: 0.6444 - val_loss: 0.7336 - val_accuracy: 0.6504\n",
      "Epoch 93/100\n",
      "1555/1555 [==============================] - 1s 885us/step - loss: 0.7082 - accuracy: 0.6449 - val_loss: 0.7340 - val_accuracy: 0.6461\n",
      "Epoch 94/100\n",
      "1555/1555 [==============================] - 1s 885us/step - loss: 0.7079 - accuracy: 0.6462 - val_loss: 0.7334 - val_accuracy: 0.6475\n",
      "Epoch 95/100\n",
      "1555/1555 [==============================] - 1s 872us/step - loss: 0.7079 - accuracy: 0.6463 - val_loss: 0.7342 - val_accuracy: 0.6498\n",
      "Epoch 96/100\n",
      "1555/1555 [==============================] - 1s 865us/step - loss: 0.7092 - accuracy: 0.6449 - val_loss: 0.7349 - val_accuracy: 0.6490\n",
      "Epoch 97/100\n",
      "1555/1555 [==============================] - 1s 869us/step - loss: 0.7079 - accuracy: 0.6459 - val_loss: 0.7341 - val_accuracy: 0.6478\n",
      "Epoch 98/100\n",
      "1555/1555 [==============================] - 1s 867us/step - loss: 0.7078 - accuracy: 0.6464 - val_loss: 0.7340 - val_accuracy: 0.6464\n",
      "Epoch 99/100\n",
      "1555/1555 [==============================] - 1s 871us/step - loss: 0.7086 - accuracy: 0.6462 - val_loss: 0.7331 - val_accuracy: 0.6477\n",
      "Epoch 100/100\n",
      "1555/1555 [==============================] - 1s 867us/step - loss: 0.7073 - accuracy: 0.6456 - val_loss: 0.7336 - val_accuracy: 0.6497\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mean_squared_error',\n",
    "                    optimizer='adam')\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"autoencoder_fraud.h5\",\n",
    "                               save_best_only=True,\n",
    "                               verbose=0)\n",
    "\n",
    "tb = TensorBoard(log_dir='./logs',\n",
    "                histogram_freq=0,\n",
    "                write_graph=True,\n",
    "                write_images=True)\n",
    "\n",
    "history = autoencoder.fit(train_x, train_x,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(test_x, test_x),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, tb]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = load_model('autoencoder_fraud.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seems like our model work nicely, now we will make the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = autoencoder.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean(np.power(test_x - pred, 2), axis=1)\n",
    "error_df = pd.DataFrame({'Reconstruction_error': mse,\n",
    "                        'True_class': test_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([76.24884869,  0.8747367 ,  0.28772556, ...,  0.60237199,\n",
       "        0.24291534,  0.20926795])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df.Reconstruction_error.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use a threshold to separate between fraudulent transactions and legitimate transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_fixed = 5\n",
    "pred_y = [1 if e > threshold_fixed else 0 for e in error_df.Reconstruction_error.values]\n",
    "matrix = confusion_matrix(error_df.True_class, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpos = matrix[0][0]\n",
    "fneg = matrix[1][1]\n",
    "fpos = matrix[0][1]\n",
    "tneg = matrix[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.86%\n",
      "Cohen Kappa: 0.163\n",
      "Sensitivity/Recall for Model : 0.71\n",
      "F1 Score for Model : 0.17\n"
     ]
    }
   ],
   "source": [
    "print( 'Accuracy: '+ str(np.round(100*float(tpos+fneg)/float(tpos+fneg + fpos + tneg),2))+'%')\n",
    "print( 'Cohen Kappa: '+ str(np.round(cohen_kappa_score(error_df.True_class, pred_y),3)))\n",
    "print(\"Sensitivity/Recall for Model : {}\".format(round(recall_score(error_df.True_class, pred_y), 2)))\n",
    "print(\"F1 Score for Model : {}\".format(round(f1_score(error_df.True_class, pred_y), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 7.83283263e-03,  1.81794483e-02,  4.64290641e-02,\n",
       "          6.84774481e-03, -3.31715077e-01, -1.31202489e-01,\n",
       "          5.77293225e-02,  6.67805299e-02,  1.57579109e-02,\n",
       "         -1.87271438e-03,  3.57544050e-03, -4.13621496e-03,\n",
       "          1.64959151e-02,  2.00457051e-02],\n",
       "        [-2.29310524e-02, -2.22983602e-02,  4.41750996e-02,\n",
       "         -1.19867399e-02,  1.57542244e-01, -1.21830001e-01,\n",
       "         -4.73055430e-03, -1.96694024e-03, -1.71357915e-02,\n",
       "          4.74945381e-02,  1.00916205e-02,  1.14347048e-01,\n",
       "         -9.07412544e-03,  8.34963262e-01],\n",
       "        [ 1.04625128e-01,  3.76095772e-02, -4.51543555e-02,\n",
       "          1.86269954e-02, -1.99588593e-02,  6.64867312e-02,\n",
       "         -8.79234299e-02, -6.98668929e-03, -3.33630783e-03,\n",
       "         -1.94845181e-02,  1.05314539e-03, -7.89478198e-02,\n",
       "         -1.00242840e-02, -2.69609123e-01],\n",
       "        [-3.18020619e-02, -7.90971294e-02, -1.00959517e-01,\n",
       "         -1.60492156e-02, -2.00150106e-02,  7.04556480e-02,\n",
       "          5.22674918e-02,  1.25800401e-01,  4.83849123e-02,\n",
       "         -9.82783213e-02,  1.48526896e-02,  1.26136661e-01,\n",
       "          1.81901418e-02, -2.62397707e-01],\n",
       "        [ 3.38728987e-02,  6.46296069e-02, -3.40595916e-02,\n",
       "          1.31884322e-01, -6.14784174e-02,  7.24409893e-02,\n",
       "          3.16524063e-04, -1.82797000e-01, -5.53201623e-02,\n",
       "         -3.31199877e-02, -1.40799228e-02, -2.19658315e-02,\n",
       "         -5.77318147e-02,  2.91776568e-01],\n",
       "        [-2.15459969e-02,  1.03272051e-01,  4.88890372e-02,\n",
       "         -9.83846188e-03,  2.22592577e-02,  1.54654244e-02,\n",
       "         -4.75823693e-02,  1.08340420e-01, -1.40012419e-02,\n",
       "          1.24248318e-01,  1.58559941e-02,  9.03292000e-02,\n",
       "          5.61445057e-02, -3.17429692e-01],\n",
       "        [-6.58652838e-03, -4.38293442e-02, -2.42093764e-02,\n",
       "         -1.49656329e-02, -6.67184144e-02,  2.96587404e-02,\n",
       "          1.19698914e-02, -1.37912463e-02, -2.53769383e-03,\n",
       "          8.37990284e-01,  4.39430587e-03,  1.60010904e-02,\n",
       "          6.03691302e-03, -2.49757409e-01],\n",
       "        [ 5.65837370e-03, -7.29328170e-02,  9.46626142e-02,\n",
       "         -8.80143885e-03, -1.09813638e-01, -5.59469638e-03,\n",
       "          3.04711983e-02,  1.49954543e-01, -4.61166836e-02,\n",
       "          3.44369817e-03,  7.96436220e-02,  1.66874334e-01,\n",
       "          4.01487239e-02, -3.47365469e-01],\n",
       "        [ 2.29964741e-02,  3.31238844e-02, -1.91802206e-03,\n",
       "          1.33724911e-02,  1.46932349e-01, -3.75639163e-02,\n",
       "          4.98979399e-03, -4.56685238e-02,  4.66725416e-02,\n",
       "         -1.52560789e-02,  2.48288573e-03,  7.35750794e-02,\n",
       "         -2.91417707e-02,  9.36227918e-01],\n",
       "        [ 3.52690592e-02, -7.48393089e-02,  4.55722846e-02,\n",
       "         -8.47627409e-03, -1.52549654e-01,  4.21585999e-02,\n",
       "          3.60492431e-02,  1.07025027e-01,  1.40954154e-02,\n",
       "         -1.31110087e-01,  1.94591489e-02,  3.66711676e-01,\n",
       "          8.76639485e-02,  1.05789393e-01],\n",
       "        [-5.51786609e-02, -9.09311175e-02,  7.98650384e-02,\n",
       "         -5.30105419e-02,  7.52343461e-02, -1.10647418e-01,\n",
       "          9.08040181e-02,  1.37796655e-01, -2.14475900e-01,\n",
       "          2.00622436e-03, -1.25968596e-02,  1.45304576e-01,\n",
       "          4.68297210e-03, -1.94145665e-01],\n",
       "        [ 8.39268789e-03,  1.27415374e-01, -5.35358116e-02,\n",
       "          2.15989761e-02, -1.19135700e-01,  6.63395673e-02,\n",
       "          3.48845646e-02, -1.04703628e-01, -3.12719271e-02,\n",
       "         -1.00960918e-01, -1.81234174e-03, -1.51757747e-01,\n",
       "         -2.69315779e-01,  2.75581896e-01],\n",
       "        [-4.47506756e-02, -1.05757505e-01,  5.05046658e-02,\n",
       "         -2.80468911e-02,  1.51855592e-02, -1.74994633e-01,\n",
       "         -1.70518130e-01,  1.82487592e-01, -1.03091467e-02,\n",
       "         -3.27135660e-02,  9.53191426e-04,  3.36228073e-01,\n",
       "          8.97323564e-02, -1.64995313e-01],\n",
       "        [-1.60714472e-03,  2.36612046e-03, -2.09709480e-02,\n",
       "         -1.52669178e-04,  6.04697429e-02, -6.68885782e-02,\n",
       "         -3.19630653e-02,  2.79090251e-04,  1.93404197e-03,\n",
       "         -6.71968833e-02, -5.69504825e-03,  2.86680758e-02,\n",
       "         -1.03160029e-03,  3.68884280e-02],\n",
       "        [-1.50049310e-02, -1.65719494e-01,  1.52842239e-01,\n",
       "         -3.46171111e-02,  2.75114682e-02,  5.47154993e-02,\n",
       "          1.10627888e-02,  2.30731264e-01,  6.14562184e-02,\n",
       "         -8.84510279e-02, -2.79957131e-02,  4.56145734e-01,\n",
       "          1.75518058e-02, -2.42468536e-01],\n",
       "        [ 3.98598704e-03, -5.47953695e-03,  1.05170254e-02,\n",
       "          6.98527833e-03,  1.17070186e+00, -2.67388448e-02,\n",
       "          5.86342439e-03, -1.22498222e-01,  2.71681068e-03,\n",
       "          6.74446896e-02,  8.28662980e-03, -1.81998557e-03,\n",
       "          8.46252684e-03,  8.93568471e-02],\n",
       "        [-3.52020301e-02, -1.05366580e-01,  1.05577432e-01,\n",
       "         -3.73227187e-02,  8.93764570e-02,  4.05913638e-03,\n",
       "         -7.38118142e-02,  2.42049724e-01, -6.17941357e-02,\n",
       "         -2.43114829e-02, -1.54457428e-02,  2.16732413e-01,\n",
       "          1.48046345e-01, -4.17678058e-02],\n",
       "        [-7.82054365e-02, -2.00693175e-01,  2.36466527e-01,\n",
       "         -1.17534295e-01,  1.60235435e-01,  1.03786374e-02,\n",
       "         -1.99944749e-01,  2.34747350e-01, -1.11602277e-01,\n",
       "         -1.45285934e-01, -5.99375169e-04,  3.46201599e-01,\n",
       "          3.03253323e-01, -6.49359405e-01],\n",
       "        [-3.14657651e-02, -7.56584182e-02,  9.26847160e-02,\n",
       "         -5.85033968e-02,  6.13633655e-02, -5.60852513e-03,\n",
       "         -9.42936018e-02,  1.13176867e-01, -4.94489707e-02,\n",
       "         -3.14525440e-02, -4.02951054e-03,  1.05376847e-01,\n",
       "          1.37141719e-01, -3.62010956e-01],\n",
       "        [ 4.22517164e-03,  2.51128022e-02, -3.35961208e-02,\n",
       "          3.75728793e-02,  9.82961953e-02, -2.46589482e-02,\n",
       "         -9.90128983e-03, -5.45491636e-01,  2.16683690e-02,\n",
       "          3.06675900e-02,  7.12019298e-03, -3.73408385e-02,\n",
       "         -2.90155821e-02, -2.49718428e-01],\n",
       "        [ 4.34415229e-02,  1.36784781e-02, -1.57356691e-02,\n",
       "         -5.07047540e-03, -1.18294105e-01,  1.11034594e-01,\n",
       "         -1.30151166e-02, -9.76202190e-02,  5.43366522e-02,\n",
       "          3.46276425e-02,  2.20258236e-02,  2.55567711e-02,\n",
       "         -2.54581701e-02,  3.75464678e-01],\n",
       "        [-1.03501063e-02, -6.86592516e-03, -7.53485709e-02,\n",
       "          5.35968167e-04, -7.17325956e-02,  9.88337025e-02,\n",
       "         -1.38495207e-01, -4.31695208e-02, -4.76503186e-02,\n",
       "         -9.50960666e-02,  1.08149592e-02, -7.84655437e-02,\n",
       "         -7.15297759e-02, -5.54930866e-01],\n",
       "        [-1.78704411e-03,  1.47966379e-02, -1.84830208e-03,\n",
       "          1.91059075e-02, -4.43155579e-02, -4.62833717e-02,\n",
       "          5.27841300e-02, -4.88821454e-02,  2.55627912e-02,\n",
       "          3.89239900e-02, -5.13008144e-03, -8.56450468e-04,\n",
       "          4.24024742e-03, -2.21177161e-01],\n",
       "        [-1.20486002e-02, -2.02262122e-02,  1.46469856e-02,\n",
       "          4.10534395e-03, -4.76109758e-02, -3.14463712e-02,\n",
       "         -3.63933146e-02, -2.16507148e-02,  2.54011992e-03,\n",
       "         -3.45565006e-02, -2.31153704e-02, -1.46041326e-02,\n",
       "          3.37562971e-02,  2.58492939e-02],\n",
       "        [ 3.92532162e-03, -4.62982059e-02,  1.51484329e-02,\n",
       "          1.09031713e-02,  1.27388135e-01, -2.13980526e-02,\n",
       "          4.09836844e-02,  2.33568419e-02,  2.44094189e-02,\n",
       "         -5.42591549e-02, -9.83611308e-03,  9.07846633e-03,\n",
       "          8.04221109e-02, -2.00234242e-02],\n",
       "        [ 5.42926928e-03, -5.24035189e-03,  1.09748775e-02,\n",
       "          3.97774018e-03,  2.62061328e-01, -2.23192591e-02,\n",
       "          3.32148001e-03,  6.37366772e-02, -6.89138984e-03,\n",
       "         -1.07567474e-01,  6.37110509e-03,  6.24490567e-02,\n",
       "         -2.01742649e-02,  1.27633679e+00],\n",
       "        [-3.02390754e-03,  7.64857745e-03, -8.34244303e-03,\n",
       "          5.15326299e-03,  4.84286360e-02,  1.42392311e-02,\n",
       "         -5.09318616e-03, -4.85904478e-02, -1.38166649e-02,\n",
       "          1.66894644e-02,  1.74799911e-03,  3.10902647e-03,\n",
       "         -1.62673816e-02,  1.59813657e-01],\n",
       "        [ 6.89208880e-03,  3.27530801e-02, -5.79514019e-02,\n",
       "          1.54511239e-02,  1.15378670e-01, -1.57263335e-02,\n",
       "          4.00776938e-02,  3.05311289e-03,  9.40163061e-03,\n",
       "          6.23025978e-03, -1.29642186e-03, -1.06155194e-01,\n",
       "         -1.95776317e-02,  8.27968344e-02],\n",
       "        [ 1.82163883e-02,  4.35082428e-03, -1.14178406e-02,\n",
       "         -3.78159271e-03, -1.14460312e-01,  6.45817667e-02,\n",
       "          5.36927581e-03, -4.23165911e-04, -3.40032652e-02,\n",
       "          5.23019284e-02,  4.63357009e-03,  2.50766519e-02,\n",
       "          3.78846303e-02,  3.31115633e-01],\n",
       "        [-6.53872415e-02, -3.36834006e-02,  3.10893282e-02,\n",
       "          2.47289333e-02, -7.60625482e-01, -4.24371585e-02,\n",
       "         -1.13539010e-01,  2.01558456e-01,  7.83851147e-02,\n",
       "         -9.13353562e-02,  1.22169368e-02,  4.12865989e-02,\n",
       "          8.58752280e-02,  5.11129498e-02]], dtype=float32),\n",
       " array([-0.6142841 , -0.93664914,  0.16825825, -0.84415215, -1.1308914 ,\n",
       "         0.43684483,  1.0623018 ,  2.1970015 ,  0.9812172 , -1.7483282 ,\n",
       "        -1.3829408 , -0.46947134,  1.0216924 , -2.3158946 ], dtype=float32),\n",
       " array([[ 1.0771637 ,  0.9234363 ,  0.24090144,  0.34196964,  0.17576472,\n",
       "          0.23386382, -0.15721107],\n",
       "        [-0.22260612,  0.1476519 , -0.12412865,  0.9116197 , -0.03295878,\n",
       "         -0.11555589, -0.22377941],\n",
       "        [-0.02491383, -0.12293486,  0.07853387, -0.12621117, -0.61611784,\n",
       "         -0.34641117,  0.08168332],\n",
       "        [ 0.45203847,  0.00109579, -0.3395951 ,  0.6199595 ,  0.5267564 ,\n",
       "         -0.02121272,  0.44879827],\n",
       "        [ 0.00738652, -0.02428814, -0.02434637, -0.03069185,  0.01715913,\n",
       "          0.0244884 , -0.13889265],\n",
       "        [ 0.01560195, -0.34546313, -0.03993365, -0.09330241, -0.1862784 ,\n",
       "         -0.08047211, -0.02503776],\n",
       "        [ 0.03789856, -0.07021444,  0.8341777 , -0.01014969,  0.24163133,\n",
       "          0.18901777, -0.2519949 ],\n",
       "        [-0.01009818,  0.7147472 , -0.01331082,  0.45640215,  0.50006974,\n",
       "         -0.06681625,  0.5248389 ],\n",
       "        [-0.3573591 ,  0.0817601 , -0.45265877,  0.23508605,  0.27135298,\n",
       "         -0.20806487,  0.18065764],\n",
       "        [-0.02070848,  0.00293488, -0.09742008,  0.25000632, -0.07294004,\n",
       "          0.2902198 , -0.03703403],\n",
       "        [-0.4579547 , -0.11113178,  0.60311896,  0.30660176, -0.2589738 ,\n",
       "          0.28576124,  1.0495151 ],\n",
       "        [-0.16231261, -0.17787227,  0.25358412, -0.0718634 ,  0.09109642,\n",
       "         -0.07679383, -0.0979356 ],\n",
       "        [-0.23171988, -0.10352995, -0.08320836,  0.6211028 , -0.2237279 ,\n",
       "          0.22158775, -0.19285156],\n",
       "        [-0.8802932 , -0.15316223, -0.1805763 , -0.49330375, -0.41696846,\n",
       "         -0.02824698, -0.18435296]], dtype=float32),\n",
       " array([0.82799315, 0.9338018 , 1.0900654 , 0.9902017 , 0.6272025 ,\n",
       "        1.1867704 , 0.86576724], dtype=float32),\n",
       " array([[-0.15874042,  0.530518  , -0.14916141, -0.5390144 ,  1.1549058 ,\n",
       "         -0.09445627,  0.00640595],\n",
       "        [ 0.76166403, -0.00770422, -0.49354768,  0.54705876, -0.68961203,\n",
       "          0.7466598 ,  0.69895065],\n",
       "        [-0.13828912, -0.17522153, -0.19449016,  0.9992723 ,  0.1260766 ,\n",
       "          0.20702793, -0.7272995 ],\n",
       "        [ 0.13561086, -0.2652633 ,  0.99291545, -0.17621794,  0.59902066,\n",
       "          0.6586917 , -0.3022    ],\n",
       "        [ 0.07812515, -0.61342734, -0.7683369 , -0.5283279 ,  0.32654473,\n",
       "         -0.36385274, -0.3380914 ],\n",
       "        [ 0.83855563,  0.56448066,  0.5272874 ,  0.26400575, -0.3557965 ,\n",
       "         -0.8171308 , -0.09101703],\n",
       "        [-0.07388426, -0.34337372, -0.09898883,  0.6886199 ,  0.4077396 ,\n",
       "         -0.7219168 ,  0.6743403 ]], dtype=float32),\n",
       " array([-1.219001  ,  0.40444708,  0.48137456, -1.061037  , -1.2605356 ,\n",
       "         0.10987509,  0.33799148], dtype=float32),\n",
       " array([[  1.5675304 ,  -0.03475874,   2.573727  ,   2.284068  ,\n",
       "          -2.3281696 ,  -0.4126624 ,   2.8156679 ,   0.7860207 ,\n",
       "          -1.9210709 ,   1.4496379 ,   2.880837  ,  -2.5002778 ,\n",
       "           0.6161595 ,   6.0284324 ,  -5.616926  ,   0.8601547 ,\n",
       "          -3.8079736 ,  -2.4449036 ,  -1.4074165 ,  -1.9758826 ,\n",
       "          -6.162443  ,  -1.0385524 ,   1.4993479 ,   0.21063259,\n",
       "           1.0461007 ,  -0.31963634,  -0.17038284,   1.5231076 ,\n",
       "          -0.5003043 ,  -2.3665295 ],\n",
       "        [ -1.9994287 ,   1.5288407 ,   4.3348846 ,  -2.3750942 ,\n",
       "          -1.1264639 ,  -4.028909  ,  -0.09097799,  -4.301558  ,\n",
       "           1.2918    ,  -2.4936857 ,   6.3360834 ,  -0.57588214,\n",
       "          -5.472144  ,  -2.6332114 ,  -0.63617295,   1.2887535 ,\n",
       "           2.6958165 ,   2.128118  ,   0.65286636,   1.8958441 ,\n",
       "          -3.7381012 ,   4.622405  ,  -0.76601297,   0.32537642,\n",
       "           0.08289492,  -0.07168394,   0.04652191,  -0.48174044,\n",
       "          -0.3316314 ,  -7.248258  ],\n",
       "        [  0.10372936,  -0.5082137 ,  -2.7264497 ,  -1.6771806 ,\n",
       "           2.3507016 ,   3.2244341 ,   3.3752913 ,   2.3544195 ,\n",
       "          -7.109018  ,  -0.5888043 ,  -2.869585  ,  -7.945784  ,\n",
       "          -2.8672771 ,  -2.8639104 ,  -4.5071335 ,  -1.4852389 ,\n",
       "           1.494681  ,   0.6740922 ,   0.48924735,   0.53620905,\n",
       "           3.3779836 ,  -2.9249213 ,  -0.78964823,  -0.1604445 ,\n",
       "           2.0599399 ,   0.06755909,   0.09411225,  -1.1669998 ,\n",
       "           0.22688708,   4.9623137 ],\n",
       "        [  2.0552201 ,   1.5779623 ,  -0.584955  ,  -1.460982  ,\n",
       "          -3.1886327 ,  -1.2752577 ,   1.5997157 ,   8.3958    ,\n",
       "          -4.3923106 ,   4.52221   ,   3.9794128 ,   0.10342725,\n",
       "          -3.395652  ,  -2.75169   ,  -1.6354449 ,  -3.1272352 ,\n",
       "          -0.24326627,  -0.5779208 ,  -0.09428438,  -2.0372105 ,\n",
       "          -1.2952075 ,  -1.2921121 ,  -0.614601  ,   0.67871845,\n",
       "          -0.06169019,  -1.3057927 ,  -0.41367495,  -0.88795215,\n",
       "          -0.09975781,   6.336141  ],\n",
       "        [  0.6007192 ,  -3.1648676 ,   1.8651599 ,   0.15142258,\n",
       "           9.388169  ,   0.08734875,   0.32199475,   6.335337  ,\n",
       "          -0.75213176,   0.4959484 ,   0.7358915 ,   0.67292875,\n",
       "          -1.349035  ,  -1.9135183 ,   0.29086336,  -1.842922  ,\n",
       "         -10.220913  ,  -0.19742851,   0.156058  ,   0.30399162,\n",
       "          -1.860177  ,   0.07517121,  -0.44696745,  -0.84795153,\n",
       "          -0.4396021 ,  -1.2652261 ,  -0.15883648,   0.29860944,\n",
       "          -0.5417631 ,   3.4766624 ],\n",
       "        [  1.9687812 ,   1.7128595 ,   2.1743376 ,  -3.032516  ,\n",
       "          -1.0642571 ,   5.1987605 ,  -4.4532266 ,  -3.67226   ,\n",
       "           7.0509624 ,  -0.5976571 ,  -1.9430246 ,  -0.7199402 ,\n",
       "           2.0490603 ,   2.2152984 ,   4.0087943 ,   2.702834  ,\n",
       "          -1.5620501 ,   1.2790298 ,   0.77152413,  -1.4969562 ,\n",
       "          -2.127228  ,  -9.109935  ,  -1.8659881 ,   0.1868756 ,\n",
       "          -0.3361157 ,  -0.05795589,  -0.71053773,   2.9666667 ,\n",
       "          -0.42109206,  -6.855525  ],\n",
       "        [  1.1377399 ,   0.31232232,   1.6275362 ,  -3.294048  ,\n",
       "          -0.27250218,  -2.9051507 ,   0.07646113,   4.383111  ,\n",
       "           1.0476412 ,  -8.83501   ,  -0.8299484 ,   0.84876573,\n",
       "           2.8248358 ,   1.7855989 ,   0.46805117,  -2.3487768 ,\n",
       "           3.6425698 ,   1.3192868 ,   0.98977953,  -1.9457608 ,\n",
       "           2.5575697 ,   5.255693  ,  -2.1344297 ,  -0.17949529,\n",
       "          -1.0100529 ,   0.15756494,  -0.44629413,  -1.6734327 ,\n",
       "           0.46791092,   5.4034376 ]], dtype=float32),\n",
       " array([-0.08178075, -1.2323172 , -1.0910364 , -0.89916456, -2.5063257 ,\n",
       "        -0.39099804,  1.5303786 ,  1.4780022 , -4.975812  , -1.4941211 ,\n",
       "        -0.28531435, -3.286364  , -2.2588964 , -2.7534885 , -2.1740825 ,\n",
       "        -1.4571053 , -5.955061  ,  0.20099045,  0.1059487 , -0.51293105,\n",
       "        -1.1560376 , -2.4860206 , -1.1579791 , -0.79746586, -1.1495931 ,\n",
       "        -0.5586648 , -0.14525993, -1.9836195 , -0.3759193 ,  2.0928888 ],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = autoencoder.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phe import paillier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paillier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
