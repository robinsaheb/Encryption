{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('creditcard.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n",
      "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
      "       'Class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31 columns, 2 of which are Time and Amount. The rest are output from the PCA transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not Fraud    284315\n",
       "Fraud           492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Class.value_counts().rename(index = {0:'Not Fraud', 1:'Fraud'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 285k transactions just 492 were labelled as fraudulent, it is a small percentage but may represent billions of dollars of lost revenue each year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PCA done on the dataset transformed it into standard-normal form. I will do the same to the 'time' and 'amount' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Time'] = StandardScaler().fit_transform(data['Time'].values.reshape(-1, 1))\n",
    "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data into training and testing sets, And To evaluate the performance of our model we will training our model on the legitimate transactions,only, And Reserving the correct class on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = train_test_split(data,test_size = 0.3,random_state=42)\n",
    "train_x = train_x[train_x.Class == 0] \n",
    "train_x = train_x.drop(['Class'], axis=1) \n",
    "\n",
    "\n",
    "test_y = test_x['Class']\n",
    "test_x = test_x.drop(['Class'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Autoencoder uses 4 Desnse (fully connected) layers with 14, 7, 7 and 30 neurons respectively. The first two layers are used for our encoder, the last two go for the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_x.shape[1]\n",
    "encoding_dim = int(input_dim / 2) - 1\n",
    "hidden_dim = int(encoding_dim / 2)\n",
    "learning_rate = 1e-7\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
    "decoder = Dense(hidden_dim, activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train our model for 100 epochs with a batch size of 128 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 100\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Model Checkpoint to save the best model and TensorBoard for graph visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/1555 [..............................] - ETA: 0s - loss: 0.9704 - accuracy: 0.0703WARNING:tensorflow:From /Users/sahebsingh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0106s). Check your callbacks.\n",
      "1555/1555 [==============================] - 2s 1ms/step - loss: 0.8681 - accuracy: 0.4850 - val_loss: 0.8091 - val_accuracy: 0.6188\n",
      "Epoch 2/100\n",
      "1555/1555 [==============================] - 1s 916us/step - loss: 0.7682 - accuracy: 0.6444 - val_loss: 0.7753 - val_accuracy: 0.6581\n",
      "Epoch 3/100\n",
      "1555/1555 [==============================] - 2s 999us/step - loss: 0.7491 - accuracy: 0.6589 - val_loss: 0.7644 - val_accuracy: 0.6621\n",
      "Epoch 4/100\n",
      "1555/1555 [==============================] - 2s 1ms/step - loss: 0.7379 - accuracy: 0.6624 - val_loss: 0.7542 - val_accuracy: 0.6643\n",
      "Epoch 5/100\n",
      "1555/1555 [==============================] - 2s 2ms/step - loss: 0.7301 - accuracy: 0.6671 - val_loss: 0.7487 - val_accuracy: 0.6701\n",
      "Epoch 6/100\n",
      "1555/1555 [==============================] - 2s 1ms/step - loss: 0.7256 - accuracy: 0.6731 - val_loss: 0.7459 - val_accuracy: 0.6791\n",
      "Epoch 7/100\n",
      "1555/1555 [==============================] - 2s 1ms/step - loss: 0.7220 - accuracy: 0.6780 - val_loss: 0.7422 - val_accuracy: 0.6807\n",
      "Epoch 8/100\n",
      "1555/1555 [==============================] - 1s 897us/step - loss: 0.7192 - accuracy: 0.6807 - val_loss: 0.7411 - val_accuracy: 0.6818\n",
      "Epoch 9/100\n",
      "1555/1555 [==============================] - 1s 895us/step - loss: 0.7173 - accuracy: 0.6827 - val_loss: 0.7390 - val_accuracy: 0.6879\n",
      "Epoch 10/100\n",
      "1555/1555 [==============================] - 1s 894us/step - loss: 0.7157 - accuracy: 0.6833 - val_loss: 0.7369 - val_accuracy: 0.6858\n",
      "Epoch 11/100\n",
      "1555/1555 [==============================] - 1s 886us/step - loss: 0.7140 - accuracy: 0.6838 - val_loss: 0.7361 - val_accuracy: 0.6840\n",
      "Epoch 12/100\n",
      "1555/1555 [==============================] - 1s 893us/step - loss: 0.7127 - accuracy: 0.6841 - val_loss: 0.7351 - val_accuracy: 0.6840\n",
      "Epoch 13/100\n",
      "1555/1555 [==============================] - 1s 880us/step - loss: 0.7114 - accuracy: 0.6836 - val_loss: 0.7345 - val_accuracy: 0.6877\n",
      "Epoch 14/100\n",
      "1555/1555 [==============================] - 1s 888us/step - loss: 0.7106 - accuracy: 0.6829 - val_loss: 0.7328 - val_accuracy: 0.6828\n",
      "Epoch 15/100\n",
      "1555/1555 [==============================] - 1s 895us/step - loss: 0.7097 - accuracy: 0.6838 - val_loss: 0.7321 - val_accuracy: 0.6803\n",
      "Epoch 16/100\n",
      "1555/1555 [==============================] - 1s 892us/step - loss: 0.7087 - accuracy: 0.6839 - val_loss: 0.7319 - val_accuracy: 0.6861\n",
      "Epoch 17/100\n",
      "1555/1555 [==============================] - 1s 900us/step - loss: 0.7081 - accuracy: 0.6852 - val_loss: 0.7318 - val_accuracy: 0.6832\n",
      "Epoch 18/100\n",
      "1555/1555 [==============================] - 1s 919us/step - loss: 0.7077 - accuracy: 0.6848 - val_loss: 0.7315 - val_accuracy: 0.6930\n",
      "Epoch 19/100\n",
      "1555/1555 [==============================] - 1s 924us/step - loss: 0.7070 - accuracy: 0.6859 - val_loss: 0.7296 - val_accuracy: 0.6892\n",
      "Epoch 20/100\n",
      "1555/1555 [==============================] - 1s 893us/step - loss: 0.7064 - accuracy: 0.6872 - val_loss: 0.7294 - val_accuracy: 0.6896\n",
      "Epoch 21/100\n",
      "1555/1555 [==============================] - 1s 896us/step - loss: 0.7059 - accuracy: 0.6873 - val_loss: 0.7290 - val_accuracy: 0.6887\n",
      "Epoch 22/100\n",
      "1555/1555 [==============================] - 1s 917us/step - loss: 0.7053 - accuracy: 0.6876 - val_loss: 0.7288 - val_accuracy: 0.6924\n",
      "Epoch 23/100\n",
      "1555/1555 [==============================] - 1s 903us/step - loss: 0.7051 - accuracy: 0.6889 - val_loss: 0.7288 - val_accuracy: 0.6872\n",
      "Epoch 24/100\n",
      "1555/1555 [==============================] - 1s 921us/step - loss: 0.7051 - accuracy: 0.6898 - val_loss: 0.7279 - val_accuracy: 0.6943\n",
      "Epoch 25/100\n",
      "1555/1555 [==============================] - 1s 917us/step - loss: 0.7043 - accuracy: 0.6902 - val_loss: 0.7275 - val_accuracy: 0.6924\n",
      "Epoch 26/100\n",
      "1555/1555 [==============================] - 2s 1ms/step - loss: 0.7045 - accuracy: 0.6908 - val_loss: 0.7280 - val_accuracy: 0.6862\n",
      "Epoch 27/100\n",
      "1555/1555 [==============================] - 1s 891us/step - loss: 0.7039 - accuracy: 0.6906 - val_loss: 0.7301 - val_accuracy: 0.6904\n",
      "Epoch 28/100\n",
      "1555/1555 [==============================] - 1s 933us/step - loss: 0.7036 - accuracy: 0.6903 - val_loss: 0.7272 - val_accuracy: 0.6922\n",
      "Epoch 29/100\n",
      "1555/1555 [==============================] - 2s 982us/step - loss: 0.7034 - accuracy: 0.6904 - val_loss: 0.7275 - val_accuracy: 0.6903\n",
      "Epoch 30/100\n",
      "1555/1555 [==============================] - 1s 929us/step - loss: 0.7045 - accuracy: 0.6915 - val_loss: 0.7271 - val_accuracy: 0.6929\n",
      "Epoch 31/100\n",
      "1555/1555 [==============================] - 1s 956us/step - loss: 0.7033 - accuracy: 0.6909 - val_loss: 0.7273 - val_accuracy: 0.6963\n",
      "Epoch 32/100\n",
      "1555/1555 [==============================] - 1s 871us/step - loss: 0.7029 - accuracy: 0.6908 - val_loss: 0.7263 - val_accuracy: 0.6915\n",
      "Epoch 33/100\n",
      "1555/1555 [==============================] - 1s 861us/step - loss: 0.7040 - accuracy: 0.6903 - val_loss: 0.7284 - val_accuracy: 0.6908\n",
      "Epoch 34/100\n",
      "1555/1555 [==============================] - 1s 838us/step - loss: 0.7026 - accuracy: 0.6911 - val_loss: 0.7263 - val_accuracy: 0.6873\n",
      "Epoch 35/100\n",
      "1555/1555 [==============================] - 1s 842us/step - loss: 0.7023 - accuracy: 0.6895 - val_loss: 0.7269 - val_accuracy: 0.6867\n",
      "Epoch 36/100\n",
      "1555/1555 [==============================] - 1s 848us/step - loss: 0.7022 - accuracy: 0.6908 - val_loss: 0.7256 - val_accuracy: 0.6946\n",
      "Epoch 37/100\n",
      "1555/1555 [==============================] - 1s 828us/step - loss: 0.7022 - accuracy: 0.6908 - val_loss: 0.7258 - val_accuracy: 0.6893\n",
      "Epoch 38/100\n",
      "1555/1555 [==============================] - 1s 842us/step - loss: 0.7020 - accuracy: 0.6912 - val_loss: 0.7252 - val_accuracy: 0.6944\n",
      "Epoch 39/100\n",
      "1555/1555 [==============================] - 1s 841us/step - loss: 0.7017 - accuracy: 0.6906 - val_loss: 0.7269 - val_accuracy: 0.6927\n",
      "Epoch 40/100\n",
      "1555/1555 [==============================] - 1s 842us/step - loss: 0.7019 - accuracy: 0.6914 - val_loss: 0.7255 - val_accuracy: 0.6930\n",
      "Epoch 41/100\n",
      "1555/1555 [==============================] - 1s 830us/step - loss: 0.7020 - accuracy: 0.6913 - val_loss: 0.7282 - val_accuracy: 0.6978\n",
      "Epoch 42/100\n",
      "1555/1555 [==============================] - 1s 851us/step - loss: 0.7017 - accuracy: 0.6916 - val_loss: 0.7247 - val_accuracy: 0.6961\n",
      "Epoch 43/100\n",
      "1555/1555 [==============================] - 1s 828us/step - loss: 0.7011 - accuracy: 0.6915 - val_loss: 0.7259 - val_accuracy: 0.6941\n",
      "Epoch 44/100\n",
      "1555/1555 [==============================] - 1s 842us/step - loss: 0.7009 - accuracy: 0.6927 - val_loss: 0.7254 - val_accuracy: 0.6961\n",
      "Epoch 45/100\n",
      "1555/1555 [==============================] - 1s 834us/step - loss: 0.7014 - accuracy: 0.6916 - val_loss: 0.7248 - val_accuracy: 0.6951\n",
      "Epoch 46/100\n",
      "1555/1555 [==============================] - 1s 830us/step - loss: 0.7010 - accuracy: 0.6922 - val_loss: 0.7261 - val_accuracy: 0.6919\n",
      "Epoch 47/100\n",
      "1555/1555 [==============================] - 1s 833us/step - loss: 0.7001 - accuracy: 0.6938 - val_loss: 0.7261 - val_accuracy: 0.6913\n",
      "Epoch 48/100\n",
      "1555/1555 [==============================] - 1s 831us/step - loss: 0.7002 - accuracy: 0.6944 - val_loss: 0.7272 - val_accuracy: 0.6889\n",
      "Epoch 49/100\n",
      "1555/1555 [==============================] - 1s 846us/step - loss: 0.7001 - accuracy: 0.6944 - val_loss: 0.7243 - val_accuracy: 0.6965\n",
      "Epoch 50/100\n",
      "1555/1555 [==============================] - 1s 844us/step - loss: 0.7002 - accuracy: 0.6947 - val_loss: 0.7252 - val_accuracy: 0.7005\n",
      "Epoch 51/100\n",
      "1555/1555 [==============================] - 1s 838us/step - loss: 0.6998 - accuracy: 0.6954 - val_loss: 0.7250 - val_accuracy: 0.6995\n",
      "Epoch 52/100\n",
      "1555/1555 [==============================] - 1s 833us/step - loss: 0.6996 - accuracy: 0.6960 - val_loss: 0.7250 - val_accuracy: 0.6965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "1555/1555 [==============================] - 1s 824us/step - loss: 0.6994 - accuracy: 0.6967 - val_loss: 0.7267 - val_accuracy: 0.6967\n",
      "Epoch 54/100\n",
      "1555/1555 [==============================] - 1s 822us/step - loss: 0.6995 - accuracy: 0.6961 - val_loss: 0.7244 - val_accuracy: 0.6995\n",
      "Epoch 55/100\n",
      "1555/1555 [==============================] - 1s 834us/step - loss: 0.6993 - accuracy: 0.6971 - val_loss: 0.7234 - val_accuracy: 0.7008\n",
      "Epoch 56/100\n",
      "1555/1555 [==============================] - 1s 837us/step - loss: 0.6990 - accuracy: 0.6982 - val_loss: 0.7242 - val_accuracy: 0.7027\n",
      "Epoch 57/100\n",
      "1555/1555 [==============================] - 1s 871us/step - loss: 0.6989 - accuracy: 0.6991 - val_loss: 0.7237 - val_accuracy: 0.7062\n",
      "Epoch 58/100\n",
      "1555/1555 [==============================] - 1s 821us/step - loss: 0.6988 - accuracy: 0.6985 - val_loss: 0.7248 - val_accuracy: 0.6996\n",
      "Epoch 59/100\n",
      "1555/1555 [==============================] - 1s 819us/step - loss: 0.6990 - accuracy: 0.6996 - val_loss: 0.7245 - val_accuracy: 0.7002\n",
      "Epoch 60/100\n",
      "1555/1555 [==============================] - 1s 824us/step - loss: 0.6986 - accuracy: 0.6995 - val_loss: 0.7236 - val_accuracy: 0.7026\n",
      "Epoch 61/100\n",
      "1555/1555 [==============================] - 1s 822us/step - loss: 0.6983 - accuracy: 0.6997 - val_loss: 0.7237 - val_accuracy: 0.6974\n",
      "Epoch 62/100\n",
      "1555/1555 [==============================] - 1s 847us/step - loss: 0.6982 - accuracy: 0.7000 - val_loss: 0.7247 - val_accuracy: 0.7023\n",
      "Epoch 63/100\n",
      "1555/1555 [==============================] - 1s 841us/step - loss: 0.6984 - accuracy: 0.6998 - val_loss: 0.7226 - val_accuracy: 0.7068\n",
      "Epoch 64/100\n",
      "1555/1555 [==============================] - 1s 923us/step - loss: 0.6981 - accuracy: 0.7001 - val_loss: 0.7228 - val_accuracy: 0.7024\n",
      "Epoch 65/100\n",
      "1555/1555 [==============================] - 1s 838us/step - loss: 0.6982 - accuracy: 0.7006 - val_loss: 0.7235 - val_accuracy: 0.7076\n",
      "Epoch 66/100\n",
      "1555/1555 [==============================] - 1s 837us/step - loss: 0.6982 - accuracy: 0.7008 - val_loss: 0.7220 - val_accuracy: 0.7060\n",
      "Epoch 67/100\n",
      "1555/1555 [==============================] - 1s 826us/step - loss: 0.6979 - accuracy: 0.7011 - val_loss: 0.7226 - val_accuracy: 0.7049\n",
      "Epoch 68/100\n",
      "1555/1555 [==============================] - 1s 835us/step - loss: 0.6977 - accuracy: 0.7024 - val_loss: 0.7223 - val_accuracy: 0.7027\n",
      "Epoch 69/100\n",
      "1555/1555 [==============================] - 1s 859us/step - loss: 0.6973 - accuracy: 0.7033 - val_loss: 0.7246 - val_accuracy: 0.7046\n",
      "Epoch 70/100\n",
      "1555/1555 [==============================] - 1s 828us/step - loss: 0.6973 - accuracy: 0.7041 - val_loss: 0.7220 - val_accuracy: 0.7051\n",
      "Epoch 71/100\n",
      "1555/1555 [==============================] - 1s 832us/step - loss: 0.6972 - accuracy: 0.7055 - val_loss: 0.7221 - val_accuracy: 0.7093\n",
      "Epoch 72/100\n",
      "1555/1555 [==============================] - 1s 824us/step - loss: 0.6973 - accuracy: 0.7054 - val_loss: 0.7234 - val_accuracy: 0.7053\n",
      "Epoch 73/100\n",
      "1555/1555 [==============================] - 1s 824us/step - loss: 0.6971 - accuracy: 0.7046 - val_loss: 0.7225 - val_accuracy: 0.7033\n",
      "Epoch 74/100\n",
      "1555/1555 [==============================] - 1s 839us/step - loss: 0.6973 - accuracy: 0.7051 - val_loss: 0.7220 - val_accuracy: 0.7143\n",
      "Epoch 75/100\n",
      "1555/1555 [==============================] - 1s 829us/step - loss: 0.6970 - accuracy: 0.7056 - val_loss: 0.7225 - val_accuracy: 0.7075\n",
      "Epoch 76/100\n",
      "1555/1555 [==============================] - 1s 839us/step - loss: 0.6967 - accuracy: 0.7056 - val_loss: 0.7225 - val_accuracy: 0.7062\n",
      "Epoch 77/100\n",
      "1555/1555 [==============================] - 1s 838us/step - loss: 0.6965 - accuracy: 0.7059 - val_loss: 0.7220 - val_accuracy: 0.7077\n",
      "Epoch 78/100\n",
      "1555/1555 [==============================] - 1s 833us/step - loss: 0.6970 - accuracy: 0.7057 - val_loss: 0.7225 - val_accuracy: 0.7126\n",
      "Epoch 79/100\n",
      "1555/1555 [==============================] - 1s 830us/step - loss: 0.6969 - accuracy: 0.7051 - val_loss: 0.7238 - val_accuracy: 0.7075\n",
      "Epoch 80/100\n",
      "1555/1555 [==============================] - 1s 829us/step - loss: 0.6966 - accuracy: 0.7055 - val_loss: 0.7234 - val_accuracy: 0.7073\n",
      "Epoch 81/100\n",
      "1555/1555 [==============================] - 1s 834us/step - loss: 0.6966 - accuracy: 0.7070 - val_loss: 0.7226 - val_accuracy: 0.7052\n",
      "Epoch 82/100\n",
      "1555/1555 [==============================] - 1s 826us/step - loss: 0.6965 - accuracy: 0.7067 - val_loss: 0.7228 - val_accuracy: 0.7092\n",
      "Epoch 83/100\n",
      "1555/1555 [==============================] - 1s 824us/step - loss: 0.6965 - accuracy: 0.7061 - val_loss: 0.7221 - val_accuracy: 0.7075\n",
      "Epoch 84/100\n",
      "1555/1555 [==============================] - 1s 828us/step - loss: 0.6971 - accuracy: 0.7062 - val_loss: 0.7282 - val_accuracy: 0.6976\n",
      "Epoch 85/100\n",
      "1555/1555 [==============================] - 1s 842us/step - loss: 0.6964 - accuracy: 0.7066 - val_loss: 0.7216 - val_accuracy: 0.7096\n",
      "Epoch 86/100\n",
      "1555/1555 [==============================] - 1s 839us/step - loss: 0.6961 - accuracy: 0.7075 - val_loss: 0.7214 - val_accuracy: 0.7094\n",
      "Epoch 87/100\n",
      "1555/1555 [==============================] - 1s 842us/step - loss: 0.6963 - accuracy: 0.7063 - val_loss: 0.7212 - val_accuracy: 0.7135\n",
      "Epoch 88/100\n",
      "1555/1555 [==============================] - 1s 833us/step - loss: 0.6964 - accuracy: 0.7079 - val_loss: 0.7215 - val_accuracy: 0.7042\n",
      "Epoch 89/100\n",
      "1555/1555 [==============================] - 1s 827us/step - loss: 0.6958 - accuracy: 0.7071 - val_loss: 0.7222 - val_accuracy: 0.7076\n",
      "Epoch 90/100\n",
      "1555/1555 [==============================] - 1s 831us/step - loss: 0.6962 - accuracy: 0.7067 - val_loss: 0.7235 - val_accuracy: 0.7162\n",
      "Epoch 91/100\n",
      "1555/1555 [==============================] - 1s 839us/step - loss: 0.6960 - accuracy: 0.7074 - val_loss: 0.7217 - val_accuracy: 0.7113\n",
      "Epoch 92/100\n",
      "1555/1555 [==============================] - 1s 823us/step - loss: 0.6959 - accuracy: 0.7070 - val_loss: 0.7214 - val_accuracy: 0.7055\n",
      "Epoch 93/100\n",
      "1555/1555 [==============================] - 1s 828us/step - loss: 0.6962 - accuracy: 0.7059 - val_loss: 0.7229 - val_accuracy: 0.7068\n",
      "Epoch 94/100\n",
      "1555/1555 [==============================] - 1s 827us/step - loss: 0.6959 - accuracy: 0.7070 - val_loss: 0.7233 - val_accuracy: 0.7011\n",
      "Epoch 95/100\n",
      "1555/1555 [==============================] - 1s 826us/step - loss: 0.6953 - accuracy: 0.7079 - val_loss: 0.7223 - val_accuracy: 0.7082\n",
      "Epoch 96/100\n",
      "1555/1555 [==============================] - 1s 837us/step - loss: 0.6956 - accuracy: 0.7072 - val_loss: 0.7208 - val_accuracy: 0.7104\n",
      "Epoch 97/100\n",
      "1555/1555 [==============================] - 1s 837us/step - loss: 0.6956 - accuracy: 0.7068 - val_loss: 0.7215 - val_accuracy: 0.7068\n",
      "Epoch 98/100\n",
      "1555/1555 [==============================] - 1s 839us/step - loss: 0.6957 - accuracy: 0.7070 - val_loss: 0.7231 - val_accuracy: 0.7105\n",
      "Epoch 99/100\n",
      "1555/1555 [==============================] - 1s 827us/step - loss: 0.6953 - accuracy: 0.7074 - val_loss: 0.7224 - val_accuracy: 0.7080\n",
      "Epoch 100/100\n",
      "1555/1555 [==============================] - 1s 837us/step - loss: 0.6955 - accuracy: 0.7081 - val_loss: 0.7201 - val_accuracy: 0.7118\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mean_squared_error',\n",
    "                    optimizer='adam')\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"autoencoder_fraud.h5\",\n",
    "                               save_best_only=True,\n",
    "                               verbose=0)\n",
    "\n",
    "tb = TensorBoard(log_dir='./logs',\n",
    "                histogram_freq=0,\n",
    "                write_graph=True,\n",
    "                write_images=True)\n",
    "\n",
    "history = autoencoder.fit(train_x, train_x,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(test_x, test_x),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, tb]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = load_model('autoencoder_fraud.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seems like our model work nicely, now we will make the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = autoencoder.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean(np.power(test_x - pred, 2), axis=1)\n",
    "error_df = pd.DataFrame({'Reconstruction_error': mse,\n",
    "                        'True_class': test_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([79.64739664,  0.76590125,  0.33518408, ...,  0.51196334,\n",
       "        0.25064001,  0.14842287])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df.Reconstruction_error.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use a threshold to separate between fraudulent transactions and legitimate transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_fixed = 5\n",
    "pred_y = [1 if e > threshold_fixed else 0 for e in error_df.Reconstruction_error.values]\n",
    "matrix = confusion_matrix(error_df.True_class, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpos = matrix[0][0]\n",
    "fneg = matrix[1][1]\n",
    "fpos = matrix[0][1]\n",
    "tneg = matrix[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.89%\n",
      "Cohen Kappa: 0.167\n",
      "Sensitivity/Recall for Model : 0.71\n",
      "F1 Score for Model : 0.17\n"
     ]
    }
   ],
   "source": [
    "print( 'Accuracy: '+ str(np.round(100*float(tpos+fneg)/float(tpos+fneg + fpos + tneg),2))+'%')\n",
    "print( 'Cohen Kappa: '+ str(np.round(cohen_kappa_score(error_df.True_class, pred_y),3)))\n",
    "print(\"Sensitivity/Recall for Model : {}\".format(round(recall_score(error_df.True_class, pred_y), 2)))\n",
    "print(\"F1 Score for Model : {}\".format(round(f1_score(error_df.True_class, pred_y), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 8.85858774e-01,  4.03920375e-02, -7.55206868e-02,\n",
       "         -8.18014741e-02,  3.19676963e-03,  1.31112831e-02,\n",
       "         -2.08362620e-02,  1.37643628e-02, -9.72205102e-02,\n",
       "         -1.16602732e-02,  5.15122376e-02,  1.15128504e-02,\n",
       "          7.41278529e-02, -1.22558670e-02],\n",
       "        [ 2.27661133e-02, -2.01526526e-02,  1.83842033e-02,\n",
       "          6.46041781e-02, -1.82329156e-02,  6.38193870e-03,\n",
       "         -5.35321236e-02,  2.80719269e-02,  9.25348997e-02,\n",
       "         -7.43276834e-01,  1.85807496e-02,  2.89267525e-02,\n",
       "          2.42186245e-02, -2.01113850e-01],\n",
       "        [-3.73466611e-02, -1.42197143e-02, -4.76828441e-02,\n",
       "          2.09652164e-04, -1.05277911e-01,  4.98096868e-02,\n",
       "          3.17766629e-02, -3.08207553e-02,  4.61944900e-02,\n",
       "          3.37772667e-01,  4.49017026e-02, -2.12558988e-03,\n",
       "          1.07778385e-01,  2.93340832e-01],\n",
       "        [-2.22172111e-01,  2.74157468e-02, -2.42237210e-01,\n",
       "          6.33952916e-02, -5.66504300e-02, -3.35484371e-02,\n",
       "         -7.58192316e-02,  3.89412530e-02, -5.65923005e-02,\n",
       "          3.79928768e-01,  3.53853405e-02,  1.80057790e-02,\n",
       "          4.73575667e-03, -8.75972882e-02],\n",
       "        [ 3.33949924e-02, -1.11095980e-02, -8.03997274e-04,\n",
       "         -6.19238727e-02, -3.98399740e-01,  2.03829613e-02,\n",
       "          5.49666323e-02, -1.58927427e-03,  6.58709407e-02,\n",
       "         -2.32377574e-01, -3.50688063e-02, -2.56402767e-03,\n",
       "         -3.43897231e-02,  8.64332393e-02],\n",
       "        [ 1.57225449e-02, -1.05574258e-01,  6.69927448e-02,\n",
       "          1.94485299e-02, -1.67948931e-01, -1.99215021e-02,\n",
       "         -1.93703752e-02,  4.05907165e-03, -3.55863795e-02,\n",
       "          3.62230748e-01, -1.17915206e-01,  6.72130957e-02,\n",
       "         -2.35755108e-02, -1.37663186e-01],\n",
       "        [-6.89339116e-02,  2.96335220e-02,  8.68603960e-03,\n",
       "         -5.42836525e-02,  8.64131749e-03, -1.87211465e-02,\n",
       "         -2.58926749e-01, -2.49047205e-03, -8.10989141e-02,\n",
       "          1.69218168e-01, -6.37257025e-02, -5.84214814e-02,\n",
       "         -2.92064790e-02, -7.27464184e-02],\n",
       "        [-1.69312079e-02,  1.21886022e-02,  8.69916454e-02,\n",
       "          1.51140481e-01, -2.24832967e-01, -2.61846017e-02,\n",
       "         -5.44100888e-02,  7.58380592e-02, -1.35590360e-01,\n",
       "          3.28039229e-01, -7.89080467e-03,  4.59929481e-02,\n",
       "         -6.06606007e-02,  2.69556135e-01],\n",
       "        [ 3.72188464e-02,  9.59972572e-03, -1.09130749e-02,\n",
       "         -5.26346266e-02,  1.37993861e-02,  2.75826305e-02,\n",
       "         -5.89240566e-02, -8.55938811e-03,  1.21471010e-01,\n",
       "         -3.69875133e-01, -1.23915844e-01, -2.24229787e-02,\n",
       "          2.39927117e-02, -1.35618262e-02],\n",
       "        [ 6.64580688e-02, -4.67610508e-02,  3.82545106e-02,\n",
       "          3.38319004e-01, -3.36711526e-01, -1.26333181e-02,\n",
       "         -5.20982407e-02,  5.21496078e-03, -1.71876363e-02,\n",
       "         -1.20050170e-01,  1.18752234e-02, -3.01204342e-02,\n",
       "         -4.25217263e-02, -2.37995684e-01],\n",
       "        [-1.11611754e-01,  5.51147722e-02,  2.46189311e-02,\n",
       "          1.87718466e-01,  5.72006889e-02, -3.58587988e-02,\n",
       "         -8.04291219e-02,  1.54246008e-02, -1.73610136e-01,\n",
       "          1.71197847e-01,  1.03181556e-01,  2.60140672e-02,\n",
       "          4.33049612e-02, -2.88622290e-01],\n",
       "        [ 2.00439058e-02,  5.48803946e-03, -1.40229212e-02,\n",
       "         -1.64797455e-01,  2.08519958e-02,  8.19163490e-03,\n",
       "          4.77500558e-02, -1.66305788e-02,  9.24053907e-01,\n",
       "         -1.53301701e-01,  9.06833559e-02, -4.49427143e-02,\n",
       "         -1.78165548e-02,  2.82963514e-01],\n",
       "        [-2.39553556e-01,  1.52959777e-02,  6.64271563e-02,\n",
       "          1.76122516e-01, -2.30965316e-01,  2.06254283e-03,\n",
       "         -8.33387524e-02,  3.86453047e-02, -2.99858987e-01,\n",
       "          3.11384778e-02, -2.88606752e-02,  8.86766538e-02,\n",
       "          2.78991163e-02, -2.03877270e-01],\n",
       "        [ 5.69639951e-02,  5.87502215e-03,  7.79465074e-03,\n",
       "          4.91311727e-03,  6.62179366e-02,  3.74041265e-04,\n",
       "         -1.45627949e-02, -1.25135202e-02,  1.70585364e-01,\n",
       "         -7.97074579e-04, -2.10117735e-02, -2.70733703e-02,\n",
       "         -1.74058098e-02, -6.41121566e-02],\n",
       "        [-8.63442644e-02,  2.10021734e-02,  1.20874546e-01,\n",
       "          1.71268225e-01, -2.57045835e-01,  2.56869588e-02,\n",
       "         -9.40926149e-02,  5.77187985e-02,  1.88227028e-01,\n",
       "          2.05463916e-01, -9.74182785e-02,  5.21920174e-02,\n",
       "         -4.16386388e-02, -4.32600409e-01],\n",
       "        [ 5.31358942e-02, -2.50661671e-02, -3.04576326e-02,\n",
       "          8.59293044e-02, -6.64266124e-02,  7.10153431e-02,\n",
       "         -3.14346552e-02, -1.85053740e-02, -1.09443642e-01,\n",
       "         -1.39468268e-01, -6.44207001e-02,  1.78927019e-01,\n",
       "          2.41800752e-02,  3.51748765e-02],\n",
       "        [-1.05430603e-01,  3.40284295e-02,  1.18726008e-01,\n",
       "          1.48683086e-01, -5.42898476e-01, -3.61612439e-02,\n",
       "         -1.43222213e-01,  1.48704033e-02, -1.80425383e-02,\n",
       "          6.56175464e-02,  4.21834975e-01,  8.23203996e-02,\n",
       "         -2.06665900e-02, -2.34559745e-01],\n",
       "        [-3.78271759e-01,  9.37100202e-02,  1.04992026e-02,\n",
       "          2.09781423e-01, -1.29634902e-01, -8.95916596e-02,\n",
       "         -2.00731814e-01,  3.08548845e-02, -9.18479711e-02,\n",
       "          5.31509459e-01, -5.51880226e-02,  1.10468879e-01,\n",
       "          1.82515144e-01, -6.61290765e-01],\n",
       "        [-6.35257140e-02,  4.65041809e-02,  1.07034937e-01,\n",
       "          2.04681531e-02,  2.06640795e-01,  1.22209042e-02,\n",
       "         -3.25327776e-02,  2.01983657e-02, -4.57606912e-02,\n",
       "          2.94558704e-01,  8.04391038e-03,  6.91826195e-02,\n",
       "         -6.55487925e-02, -1.64109156e-01],\n",
       "        [ 1.99687053e-02, -5.55934049e-02, -7.12255016e-03,\n",
       "         -1.81551371e-02, -2.06802577e-01,  5.12757935e-02,\n",
       "          3.28726135e-02,  1.09657738e-02, -1.19444072e-01,\n",
       "          1.33468866e-01, -4.85211462e-02, -3.22568268e-02,\n",
       "         -5.07794134e-02,  2.33463556e-01],\n",
       "        [ 4.17722352e-02,  1.45181995e-02,  2.73371115e-02,\n",
       "          3.47073637e-02, -1.01703376e-01,  1.74022485e-02,\n",
       "          4.65557203e-02,  7.31882267e-03, -7.53702298e-02,\n",
       "         -5.58900982e-02,  3.89860243e-01,  6.29212409e-02,\n",
       "         -4.30679834e-03, -5.06162904e-02],\n",
       "        [ 6.85129091e-02, -1.30024711e-02, -4.04677875e-02,\n",
       "         -8.53654817e-02, -8.08655471e-02,  4.77472916e-02,\n",
       "          7.37547949e-02, -2.19733417e-02,  3.78185418e-04,\n",
       "          5.90794384e-01,  1.76411435e-01,  3.13970894e-02,\n",
       "          4.43820236e-03,  3.47691029e-01],\n",
       "        [ 5.34984767e-01,  3.68883610e-02, -1.79441012e-02,\n",
       "         -5.48640378e-02, -1.56907380e-01,  2.41786707e-03,\n",
       "         -5.16215190e-02,  8.64874601e-05, -1.63030066e-02,\n",
       "          2.69794166e-01,  4.09677885e-02,  1.11201704e-02,\n",
       "         -1.04597711e-04, -5.41636832e-02],\n",
       "        [ 4.06671166e-01,  3.33182444e-03, -6.81923702e-02,\n",
       "         -4.99410462e-03,  3.45886387e-02, -1.25293126e-02,\n",
       "          3.85547541e-02, -5.71380649e-03, -3.64519842e-02,\n",
       "          1.90163538e-01,  3.90453003e-02, -1.08491071e-02,\n",
       "          4.22520079e-02,  2.91815214e-02],\n",
       "        [-4.63515427e-03,  2.18427796e-02,  2.45269109e-03,\n",
       "         -4.08457816e-02, -7.75525393e-03, -8.14713538e-03,\n",
       "         -1.10342167e-02, -1.82116181e-02, -6.17433041e-02,\n",
       "          5.74850058e-03, -7.80227631e-02, -1.16397701e-02,\n",
       "         -1.71699189e-02,  1.01049542e-02],\n",
       "        [ 3.07467561e-02, -2.00981018e-03, -1.92641038e-02,\n",
       "          4.72526625e-02, -3.04258373e-02,  1.18206104e-03,\n",
       "         -1.18694222e-02, -5.57842245e-03,  9.47788917e-03,\n",
       "         -1.15682781e+00, -9.73059051e-03, -1.02518955e-02,\n",
       "          2.61625461e-02, -8.88034478e-02],\n",
       "        [-2.55286926e-03, -1.60989445e-02, -2.08239686e-02,\n",
       "         -1.61002227e-03, -5.04074618e-03,  1.53364530e-02,\n",
       "          1.13671310e-02,  2.49768719e-02, -3.75321582e-02,\n",
       "         -1.62599012e-01, -4.16537933e-02, -2.59922985e-02,\n",
       "          1.20820524e-02,  3.72516103e-02],\n",
       "        [-9.11387950e-02,  1.23591116e-02, -1.73653364e-02,\n",
       "         -7.03201890e-02,  3.38894501e-02,  9.56644863e-03,\n",
       "          2.55888924e-02,  1.27031654e-02,  7.69481584e-02,\n",
       "          2.54142992e-02,  6.13109116e-03, -3.11235934e-02,\n",
       "         -1.40194772e-02,  1.52131543e-01],\n",
       "        [ 1.93654418e-01,  3.54955671e-04, -1.35303158e-02,\n",
       "          2.48006489e-02, -8.74951668e-03,  7.93180987e-03,\n",
       "         -2.95580681e-02,  1.18709522e-05,  1.80492084e-02,\n",
       "          1.47386700e-01,  1.03800468e-01, -9.74714663e-03,\n",
       "          1.14652542e-02, -4.17542681e-02],\n",
       "        [-6.64166138e-02,  6.82839081e-02,  2.07687188e-02,\n",
       "          1.42053654e-02,  1.55128753e-02, -8.93936828e-02,\n",
       "          1.17724827e-02,  2.64730565e-02, -4.51485574e-01,\n",
       "          2.00601816e-01, -1.96665689e-01,  4.66474593e-02,\n",
       "          2.47477144e-02, -1.45643175e-01]], dtype=float32),\n",
       " array([-0.99163646,  0.6118678 ,  0.5541229 , -1.1914736 ,  0.88109916,\n",
       "        -0.3323169 ,  0.8282694 , -1.7253573 , -1.0317432 ,  1.8170027 ,\n",
       "        -1.5801138 , -0.26002812, -0.7864305 , -0.6217412 ], dtype=float32),\n",
       " array([[ 0.04962632, -0.13626713, -0.14129886,  0.06910769, -0.40453187,\n",
       "          0.00853235, -0.10863302],\n",
       "        [-0.0587493 ,  0.0530848 ,  0.21731725,  0.09129838, -0.09306048,\n",
       "         -0.09852047, -0.44402793],\n",
       "        [ 0.07336827,  0.07982407,  0.09010691,  0.21935818, -0.17621683,\n",
       "          0.25288615,  0.1991938 ],\n",
       "        [ 0.25649023, -0.02101238,  0.03480445,  0.0146017 , -0.00990294,\n",
       "          0.01524334, -0.8005743 ],\n",
       "        [ 0.15937766, -0.19920704,  0.31414673, -0.12564902, -0.37559083,\n",
       "         -0.20619358,  0.19637837],\n",
       "        [ 0.69618464, -0.46231443,  0.21088481, -0.11071276, -0.14689319,\n",
       "          0.30778173,  0.02860513],\n",
       "        [ 0.43000373, -0.15640073, -0.12815465, -0.07319857, -0.28115302,\n",
       "         -0.39617229,  0.08353581],\n",
       "        [-0.5981984 ,  0.85824656, -0.27591318, -1.0311356 , -0.8985179 ,\n",
       "          0.57707655, -0.5935929 ],\n",
       "        [-0.0520931 , -0.06185414,  0.06040528,  0.0922245 ,  0.07972087,\n",
       "         -0.00998715,  0.00186517],\n",
       "        [ 0.51764023, -0.12748152, -0.19992517, -0.2627615 , -0.20399912,\n",
       "          0.1361289 ,  0.07247912],\n",
       "        [ 0.29384515, -0.07028876, -0.09120086, -0.02521765, -0.0860275 ,\n",
       "         -0.85326564,  0.02909261],\n",
       "        [-0.328706  ,  0.33742633,  0.16995105, -0.03176573,  0.4247545 ,\n",
       "         -0.23244846,  0.23267277],\n",
       "        [ 0.39535293,  0.17911671,  0.03049849,  0.3153954 ,  0.01652037,\n",
       "          0.43779078,  0.46410406],\n",
       "        [ 0.25943303, -0.03535031, -0.08781866, -0.12416852, -0.08215922,\n",
       "          0.01613389,  0.08449846]], dtype=float32),\n",
       " array([0.6911213 , 1.2054724 , 0.8101382 , 0.5971277 , 0.57832694,\n",
       "        0.68725425, 0.55842745], dtype=float32),\n",
       " array([[ 0.36318946,  0.2443071 ,  0.25746667,  0.6622747 ,  0.14980033,\n",
       "         -0.06393693, -0.42560023],\n",
       "        [ 0.12811403, -0.5323783 , -0.9340285 ,  0.3922184 ,  0.93498963,\n",
       "          0.28047073, -0.90705144],\n",
       "        [ 0.8695784 , -0.14765376, -0.4471774 ,  0.14795305,  0.43669266,\n",
       "          0.5339256 ,  0.70837873],\n",
       "        [ 0.22193685, -0.21087292,  0.5808412 , -0.3969381 ,  0.47552127,\n",
       "         -0.670881  , -0.4630335 ],\n",
       "        [ 0.24120764, -0.23449115,  0.6296637 ,  0.21287994, -0.69778746,\n",
       "         -0.06628093, -0.11516521],\n",
       "        [-0.22151974, -0.16983639,  0.33249182,  0.37730777,  0.24496819,\n",
       "         -0.1562867 ,  1.1429491 ],\n",
       "        [-0.1551112 ,  0.03613509, -0.72455084, -0.1913048 , -0.51666707,\n",
       "         -0.7516507 , -0.01340458]], dtype=float32),\n",
       " array([-1.4859546 ,  0.55834824,  0.27487648, -0.6354962 , -0.32728398,\n",
       "         1.3994348 ,  0.15525462], dtype=float32),\n",
       " array([[-1.15183532e+00,  3.10503435e+00,  2.79856110e+00,\n",
       "         -2.18962169e+00, -4.93664217e+00, -8.54816437e+00,\n",
       "         -5.34268951e+00, -7.85549784e+00,  2.84315252e+00,\n",
       "          1.32232594e+00, -9.98336315e-01,  2.95021534e+00,\n",
       "          1.39472103e+00,  1.56825411e+00,  2.21427393e+00,\n",
       "          6.16737652e+00,  8.09089720e-01,  1.40857255e+00,\n",
       "          5.40764236e+00, -5.04073143e+00, -8.87973905e-01,\n",
       "          4.78006810e-01, -1.45145786e+00, -9.71440411e+00,\n",
       "         -1.67086351e+00,  9.39446568e-01, -2.78648108e-01,\n",
       "          2.62046027e+00, -3.99706721e+00, -6.81206942e+00],\n",
       "        [ 1.14140522e+00, -1.73983181e+00,  6.26843393e-01,\n",
       "          8.38823557e-01, -5.23226643e+00, -2.14952636e+00,\n",
       "         -4.49769688e+00, -9.16352749e-01, -1.64598212e-01,\n",
       "          1.99676168e+00,  7.26330042e-01,  2.26314282e+00,\n",
       "          1.98964500e+00,  3.29340458e+00,  2.31433153e+00,\n",
       "         -5.91172361e+00,  1.22842872e+00, -1.70330429e+00,\n",
       "          8.35532284e+00,  2.62243223e+00, -8.36332858e-01,\n",
       "          1.04150648e+01,  2.01398230e+00,  3.41773605e+00,\n",
       "         -1.41523635e+00, -1.50466383e+00,  4.75765735e-01,\n",
       "          2.10993457e+00,  2.03022510e-01, -5.37596083e+00],\n",
       "        [-7.95620158e-02,  1.03866017e+00,  1.79258847e+00,\n",
       "          9.74793434e-01,  2.81016588e+00, -4.01646900e+00,\n",
       "         -1.61227906e+00, -5.35385084e+00,  1.00179625e+00,\n",
       "          3.61148715e+00,  5.01550245e+00,  2.00879145e+00,\n",
       "          1.04472779e-01,  5.75029087e+00,  3.88171697e+00,\n",
       "         -1.61485529e+00,  7.97540605e-01, -1.90360749e+00,\n",
       "         -4.79725885e+00,  2.77605605e+00, -2.91413808e+00,\n",
       "          2.08360958e+00,  8.51496875e-01, -1.15879345e+00,\n",
       "         -1.63750839e+00,  5.64246364e-02, -5.12036502e-01,\n",
       "          1.37733623e-01,  5.07864285e+00, -6.34166002e+00],\n",
       "        [-9.17696476e-01, -4.98613024e+00,  3.05287862e+00,\n",
       "         -1.97516489e+00,  1.91929328e+00, -5.30340767e+00,\n",
       "          2.13674474e+00,  8.24073124e+00,  2.27768087e+00,\n",
       "         -5.98799706e-01,  2.32726693e+00, -3.95927739e+00,\n",
       "          1.92308581e+00, -3.07129359e+00, -1.66024148e+00,\n",
       "          5.98333883e+00, -3.27501011e+00,  1.72351253e+00,\n",
       "         -4.36780596e+00,  5.09828758e+00,  4.99757618e-01,\n",
       "          4.41442919e+00, -1.67381454e+00, -5.77907515e+00,\n",
       "         -4.97720271e-01, -1.75642803e-01, -7.14727223e-01,\n",
       "         -1.01902497e+00, -1.22215295e+00,  4.56373739e+00],\n",
       "        [ 1.43818259e+00,  1.53989792e+00,  1.32409179e+00,\n",
       "         -5.77336025e+00, -4.31343228e-01, -7.98213959e+00,\n",
       "         -3.35956961e-01,  2.84696150e+00,  1.20054841e+00,\n",
       "          1.57738018e+00,  2.16446900e+00, -4.19431019e+00,\n",
       "         -8.99955213e-01, -2.36717510e+00, -1.34553480e+00,\n",
       "         -4.72979116e+00, -1.58950186e+00,  1.23541677e+00,\n",
       "         -8.96023393e-01, -4.38244438e+00,  2.11912704e+00,\n",
       "         -8.02201557e+00,  1.05665696e+00, -1.01948474e-02,\n",
       "         -1.80291498e+00, -8.89112055e-01,  9.44800913e-01,\n",
       "          2.93766320e-01,  3.80885983e+00,  4.52218103e+00],\n",
       "        [-1.06488526e+00, -1.41138935e+00, -3.52411699e+00,\n",
       "          5.45492935e+00, -1.87765121e+00, -5.36961269e+00,\n",
       "          2.45734262e+00,  3.95093822e+00, -2.19245887e+00,\n",
       "          3.77264214e+00, -1.62141502e-01, -3.25304365e+00,\n",
       "         -1.22306764e+00, -1.27159715e+00, -2.78108263e+00,\n",
       "          3.24467587e+00, -6.07579276e-02, -3.83539271e+00,\n",
       "          6.71554041e+00,  1.52509534e+00,  3.53146005e+00,\n",
       "         -6.77867126e+00, -7.66053498e-01,  3.01869798e+00,\n",
       "         -5.72023809e-01,  3.30847204e-01, -9.98201251e-01,\n",
       "         -4.43927377e-01,  8.93746376e-01,  6.24524927e+00],\n",
       "        [-1.16159938e-01, -3.04602087e-01, -8.47116828e-01,\n",
       "          3.03972751e-01, -3.07479048e+00,  2.76176119e+00,\n",
       "          5.28847456e+00, -1.16854995e-01,  3.10360003e+00,\n",
       "          1.11988473e+00, -4.16841698e+00,  9.92928565e-01,\n",
       "          1.48900366e+00,  1.66030073e+00,  2.08145213e+00,\n",
       "          6.54838562e-01, -3.37822247e+00, -8.87705445e-01,\n",
       "          6.38488102e+00,  4.49067354e+00, -7.04774952e+00,\n",
       "         -1.68549991e+00, -1.94329977e-01, -1.63688064e+00,\n",
       "          3.21270728e+00,  5.40036708e-02,  1.43584162e-01,\n",
       "         -4.88495141e-01,  1.00751448e+00, -2.07827568e+00]], dtype=float32),\n",
       " array([ 0.5909245 , -2.1608708 ,  0.1402002 , -0.60120875,  0.17050594,\n",
       "        -0.2033457 ,  0.8655459 ,  1.2530547 , -0.69730824, -0.5716347 ,\n",
       "        -1.4655124 , -1.4040737 , -0.8073903 , -2.2950907 , -1.2062368 ,\n",
       "        -2.6902905 , -1.3385173 , -0.11910265, -2.7353296 , -1.8937923 ,\n",
       "        -2.1439269 , -6.8429236 , -0.28136083, -3.3797507 , -1.0670933 ,\n",
       "        -0.80878264, -0.5239354 , -1.4676955 , -4.3725023 ,  0.8368532 ],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = autoencoder.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
